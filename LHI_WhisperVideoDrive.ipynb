{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/LifeHackInnovationsLLC/whisper-video-transcription/blob/main/LHI_WhisperVideoDrive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSzWV5We2jx0"
   },
   "source": [
    "If you're looking at this on GitHub and new to Python Notebooks or Colab, click the Google Colab badge above 👆\n",
    "\n",
    "#📼 OpenAI Whisper + Google Drive Video Transcription\n",
    "\n",
    "📺 Getting started video: https://youtu.be/YGpYinji7II\n",
    "\n",
    "###This application will extract audio from all the video files in a Google Drive folder and create a high-quality transcription with OpenAI's Whisper automatic speech recognition system.\n",
    "\n",
    "*Note: This requires giving the application permission to connect to your drive. Only you will have access to the contents of your drive, but please read the warnings carefully.*\n",
    "\n",
    "This notebook application:\n",
    "1. Connects to your Google Drive when you give it permission.\n",
    "2. Creates a WhisperVideo folder and three subfolders (ProcessedVideo, AudioFiles and TextFiles.)\n",
    "3. When you run the application it will search for all the video files (.mp4, .mov, mkv and .avi) in your WhisperVideo folder, transcribe them and then move the file to WhisperVideo/ProcessedVideo and save the transcripts to WhisperVideo/TextFiles. It will also add a copy of the new audio file to WhisperVideo/AudioFiles\n",
    "\n",
    "###**For faster performance set your runtime to \"GPU\"**\n",
    "*Click on \"Runtime\" in the menu and click \"Change runtime type\". Select \"GPU\".*\n",
    "\n",
    "\n",
    "**Note: If you add a new file after running this application you'll need to remount the drive in step 1 to make them searchable**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHhCHnaeTYw8"
   },
   "source": [
    "##0. Choose which 'LHI Client' or folder to add transcriptions to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L20Y96kiPz1R",
    "lines_to_next_cell": 2,
    "outputId": "b7bdd274-635d-4d43-d73b-154b9d62d148"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking /content/drive status...\n",
      "Mounting Google Drive...\n",
      "Mounted at /content/drive\n",
      "Google Drive mounted successfully.\n",
      "Drive is mounted and ready.\n",
      "Proceeding with folder creation...\n",
      "Select a client folder:\n",
      "1: WCBradley\n",
      "2: SiriusXM\n",
      "3: LHI\n",
      "4: Enter a custom folder path\n",
      "Enter the number corresponding to your choice (default: 1): 1\n",
      "Checking folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/\n",
      "Folder already exists: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/\n",
      "Checking folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/\n",
      "Created folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/\n",
      "Checking folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/\n",
      "Created folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/\n",
      "Checking folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/\n",
      "Created folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/\n",
      "WhisperVideo folder and subfolders initialized for client:\n",
      "WhisperVideo folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/\n",
      "Audio files folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/\n",
      "Text files folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/\n",
      "Processed videos folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Reusable function to check and mount Google Drive\n",
    "def check_and_mount_drive():\n",
    "    print(\"Checking /content/drive status...\")\n",
    "    if os.path.exists(\"/content/drive\"):\n",
    "        print(\"Mount directory exists. Checking contents...\")\n",
    "        if os.listdir(\"/content/drive\"):\n",
    "            print(\"Mountpoint already contains files. Attempting to unmount...\")\n",
    "            try:\n",
    "                # Unmount the existing mountpoint\n",
    "                !fusermount -u /content/drive\n",
    "                print(\"Unmounted successfully.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to unmount: {e}\")\n",
    "                print(\"If the issue persists, please select 'Runtime > Disconnect and delete runtime' and try again.\")\n",
    "                return False\n",
    "\n",
    "    # Mount Google Drive\n",
    "    print(\"Mounting Google Drive...\")\n",
    "    from google.colab import drive\n",
    "    try:\n",
    "        drive.mount(\"/content/drive\", force_remount=True)\n",
    "        print(\"Google Drive mounted successfully.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Mounting failed: {e}\")\n",
    "        print(\"If the issue persists, please select 'Runtime > Disconnect and delete runtime' and try again.\")\n",
    "        return False\n",
    "\n",
    "    # Verify mount\n",
    "    if os.path.exists(\"/content/drive/MyDrive\"):\n",
    "        print(\"Drive is mounted and ready.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Mounting seems incomplete. Please check your drive configuration.\")\n",
    "        return False\n",
    "\n",
    "# Attempt to check and mount the drive\n",
    "if check_and_mount_drive():\n",
    "    print(\"Proceeding with folder creation...\")\n",
    "else:\n",
    "    print(\"Drive mount failed. Cannot proceed.\")\n",
    "    raise SystemExit(\"Drive mount failed. Exiting.\")\n",
    "\n",
    "# Predefined options for client folders\n",
    "clients = {\n",
    "    \"1\": \"/content/drive/MyDrive/Clients/WCBradley/Videos/\",\n",
    "    \"2\": \"/content/drive/MyDrive/Clients/SiriusXM/Videos/\",\n",
    "    \"3\": \"/content/drive/MyDrive/Clients/LHI/Videos/\"\n",
    "}\n",
    "\n",
    "# Display options to the user\n",
    "print(\"Select a client folder:\")\n",
    "print(\"1: WCBradley\")\n",
    "print(\"2: SiriusXM\")\n",
    "print(\"3: LHI\")\n",
    "print(\"4: Enter a custom folder path\")\n",
    "\n",
    "# Get user input\n",
    "choice = input(\"Enter the number corresponding to your choice (default: 1): \").strip()\n",
    "\n",
    "# Determine the root folder for the client\n",
    "if choice in clients:\n",
    "    client_videos_folder = clients[choice]\n",
    "elif choice == \"4\":\n",
    "    client_videos_folder = input(\"Enter the full path to your Videos folder: \").strip()\n",
    "else:\n",
    "    # Default to WCBradley if no valid input\n",
    "    client_videos_folder = clients[\"1\"]\n",
    "\n",
    "# Define the WhisperVideo root folder within the client's Videos folder\n",
    "rootFolder = client_videos_folder + \"WhisperVideo/\"\n",
    "\n",
    "# Define subfolder paths relative to the WhisperVideo root folder\n",
    "audio_folder = rootFolder + \"AudioFiles/\"\n",
    "text_folder = rootFolder + \"TextFiles/\"\n",
    "processed_folder = rootFolder + \"ProcessedVideo/\"\n",
    "\n",
    "# Ensure WhisperVideo folder and its subfolders exist\n",
    "folders = [rootFolder, audio_folder, text_folder, processed_folder]\n",
    "for folder in folders:\n",
    "    try:\n",
    "        print(f\"Checking folder: {folder}\")\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "            print(f\"Created folder: {folder}\")\n",
    "        else:\n",
    "            print(f\"Folder already exists: {folder}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error ensuring folder {folder}: {e}\")\n",
    "\n",
    "print(f\"WhisperVideo folder and subfolders initialized for client:\")\n",
    "print(f\"WhisperVideo folder: {rootFolder}\")\n",
    "print(f\"Audio files folder: {audio_folder}\")\n",
    "print(f\"Text files folder: {text_folder}\")\n",
    "print(f\"Processed videos folder: {processed_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFx0mfr031aw"
   },
   "source": [
    "##1. Load the code libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PomTPiCR5ihc",
    "outputId": "bcb695ef-5838-4815-c862-132c09817166"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-jdhtpc0f\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-jdhtpc0f\n",
      "  Resolved https://github.com/openai/whisper.git to commit 90db0de1896c23cbfaf0c58bc2d30665f709f170\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (1.26.4)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (2.5.1+cu121)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (4.66.6)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (10.5.0)\n",
      "Collecting tiktoken (from openai-whisper==20240930)\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting triton>=2.0.0 (from openai-whisper==20240930)\n",
      "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper==20240930) (3.16.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
      "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803583 sha256=9e7205b554d914e5f79ac2ebd3d3ff45c9c62d3cd39bc3f134b94966a001893b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9pok1zxw/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: triton, tiktoken, openai-whisper\n",
      "Successfully installed openai-whisper-20240930 tiktoken-0.8.0 triton-3.1.0\n",
      "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
      "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
      "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Hit:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
      "Hit:7 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
      "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
      "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
      "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,629 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,755 kB]\n",
      "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,548 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,516 kB]\n",
      "Fetched 15.7 MB in 4s (3,654 kB/s)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "51 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n",
      "Requirement already satisfied: audioread in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 139M/139M [00:40<00:00, 3.62MiB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git\n",
    "!sudo apt update && sudo apt install ffmpeg\n",
    "!pip install librosa\n",
    "!pip install audioread\n",
    "\n",
    "import whisper\n",
    "import time\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import re\n",
    "import os\n",
    "\n",
    "# model = whisper.load_model(\"tiny.en\")\n",
    "model = whisper.load_model(\"base.en\")\n",
    "# model = whisper.load_model(\"small.en\") # load the small model\n",
    "# model = whisper.load_model(\"medium.en\")\n",
    "# model = whisper.load_model(\"large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIjETRxb5nuE"
   },
   "source": [
    "##2. Give the application permission to mount the drive and create the folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zxWvhDHzmspd",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# # Mount Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\", force_remount=True)  # This will prompt for authorization.\n",
    "\n",
    "# import os\n",
    "\n",
    "# # Ensure WhisperVideo folder and its subfolders exist\n",
    "# folders = [rootFolder, audio_folder, text_folder, processed_folder]\n",
    "# for folder in folders:\n",
    "#     try:\n",
    "#         if not os.path.exists(folder):\n",
    "#             os.makedirs(folder)\n",
    "#             print(f\"Created folder: {folder}\")\n",
    "#         else:\n",
    "#             print(f\"Folder already exists: {folder}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error ensuring folder {folder}: {e}\")\n",
    "\n",
    "# print(f\"All folders verified and ready under: {rootFolder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fr8tBQy5Tvo"
   },
   "source": [
    "##3. Upload any video files you want transcribed in the \"WhisperVideo\" folder in your Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCef9V2i392e"
   },
   "source": [
    "## 4. Extract audio from the video files and create a transcription\n",
    "\n",
    "This step processes video files in the `WhisperVideo` folder by extracting audio, transcribing it, and saving the transcription in the `TextFiles` folder. The original video file is moved to the `ProcessedVideo` folder upon successful transcription.\n",
    "\n",
    "### Shareable Links\n",
    "The shareable link for the processed video is generated based on its Google Drive file path. This method avoids additional API calls and assumes that files are already shared within your team. The constructed link can be found at the beginning of the transcription file.\n",
    "\n",
    "Example of a shareable link format:\n",
    "```\n",
    "https://drive.google.com/file/d/<file_id>/view\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D_rB5M99nmhw",
    "lines_to_next_cell": 2,
    "outputId": "59e251c7-81a2-4c92-ac70-ad4e94b25ad4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting audio for Second Standup.mov to /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/Second Standup.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-8afb492a4905>:60: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(video_path, sr=16000)  # Load audio with 16 kHz sampling rate\n",
      "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio extraction successful using librosa for Second Standup.mov\n",
      "Starting transcription for /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/Second Standup.wav\n",
      "Transcription completed for /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/Second Standup.wav\n",
      "Saving transcription to /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/Second Standup.txt\n",
      "Transcription saved successfully for Second Standup.mov\n",
      "Moving file Second Standup.mov to processed folder\n",
      "File moved to processed folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/Second Standup.mov\n",
      "Successfully processed Second Standup.mov\n",
      "Extracting audio for Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).mov to /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-8afb492a4905>:60: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(video_path, sr=16000)  # Load audio with 16 kHz sampling rate\n",
      "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio extraction successful using librosa for Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).mov\n",
      "Starting transcription for /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).wav\n",
      "Transcription completed for /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).wav\n",
      "Saving transcription to /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).txt\n",
      "Transcription saved successfully for Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).mov\n",
      "Moving file Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).mov to processed folder\n",
      "File moved to processed folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).mov\n",
      "Successfully processed Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).mov\n",
      "Processing Report\n",
      "\n",
      "Successfully Processed Files (2):\n",
      "Second Standup.mov\n",
      "Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).mov\n",
      "\n",
      "Skipped Files (0):\n",
      "\n",
      "\n",
      "Errors (0):\n",
      "\n",
      "\n",
      "Folder Parity Check:\n",
      "All folders have matching files: Yes\n",
      "Processed Videos: 2\n",
      "Audio Files: 2\n",
      "Text Files: 2\n",
      "\n",
      "\n",
      "Current CSV log entries:\n",
      "Timestamp,FileName,Status,Notes\n",
      "2024-12-16 01:11:44,Second Standup.mov,Processed,\n",
      "2024-12-16 01:11:44,Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).mov,Processed,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datetime import timedelta\n",
    "import subprocess\n",
    "import logging\n",
    "import csv\n",
    "from datetime import datetime\n",
    "# Removed: from urllib.parse import quote\n",
    "\n",
    "# Helper function to format time\n",
    "def format_time(seconds):\n",
    "    \"\"\"Convert seconds to HH:MM:SS format.\"\"\"\n",
    "    return str(timedelta(seconds=int(seconds)))\n",
    "\n",
    "# Removed the generate_shareable_link function\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    filename=\"processing_log.txt\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "\n",
    "# Ensure folders are created\n",
    "folders = [rootFolder, audio_folder, text_folder, processed_folder]\n",
    "for folder in folders:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "# Initialize logs\n",
    "success_log = []\n",
    "error_log = []\n",
    "skipped_log = []\n",
    "\n",
    "# Process all video files in WhisperVideo folder\n",
    "video_files = [f for f in os.listdir(rootFolder) if os.path.isfile(os.path.join(rootFolder, f))]\n",
    "\n",
    "for video_file in video_files:\n",
    "    # Exclude the report file from processing\n",
    "    if video_file == \"processing_report.txt\":\n",
    "        continue\n",
    "\n",
    "    # Skip non-video files\n",
    "    if not video_file.endswith((\".mp4\", \".mov\", \".avi\", \".mkv\")):\n",
    "        skipped_log.append((video_file, \"Invalid format\"))\n",
    "        print(f\"Skipped {video_file}: Invalid format.\")\n",
    "        continue\n",
    "\n",
    "    # Define paths\n",
    "    video_path = os.path.join(rootFolder, video_file)\n",
    "    audio_path = os.path.join(audio_folder, video_file[:-4] + \".wav\")\n",
    "    text_path = os.path.join(text_folder, video_file[:-4] + \".txt\")\n",
    "    processed_path = os.path.join(processed_folder, video_file)\n",
    "\n",
    "    try:\n",
    "        print(f\"Extracting audio for {video_file} to {audio_path}\")\n",
    "        # Extract audio\n",
    "        try:\n",
    "            # Attempt to load the audio using librosa\n",
    "            y, sr = librosa.load(video_path, sr=16000)  # Load audio with 16 kHz sampling rate\n",
    "            sf.write(audio_path, y, sr)  # Save audio as a WAV file\n",
    "            print(f\"Audio extraction successful using librosa for {video_file}\")\n",
    "        except Exception as e_librosa:\n",
    "            print(f\"Librosa extraction failed for {video_file}: {e_librosa}\")\n",
    "            print(f\"Falling back to ffmpeg for {video_file}\")\n",
    "            # Use ffmpeg as a fallback\n",
    "            subprocess.run([\"ffmpeg\", \"-i\", video_path, \"-ar\", \"16000\", \"-ac\", \"1\", audio_path], check=True)\n",
    "            print(f\"Audio extraction successful using ffmpeg for {video_file}\")\n",
    "\n",
    "        print(f\"Starting transcription for {audio_path}\")\n",
    "        # Transcribe the audio using Whisper\n",
    "        result = model.transcribe(audio_path)\n",
    "        print(f\"Transcription completed for {audio_path}\")\n",
    "\n",
    "        # Create initial transcription\n",
    "        text = \"\"\n",
    "        for segment in result[\"segments\"]:\n",
    "            start_time = format_time(segment[\"start\"])\n",
    "            end_time = format_time(segment[\"end\"])\n",
    "            text_segment = segment[\"text\"].strip()\n",
    "            text += f\"[{start_time} - {end_time}] {text_segment}\\n\\n\"\n",
    "\n",
    "        print(f\"Saving transcription to {text_path}\")\n",
    "        # Save the transcription\n",
    "        with open(text_path, \"w\") as f:\n",
    "            f.write(text)\n",
    "        print(f\"Transcription saved successfully for {video_file}\")\n",
    "\n",
    "        print(f\"Moving file {video_file} to processed folder\")\n",
    "        # Move the video to ProcessedVideo folder\n",
    "        shutil.move(video_path, processed_path)\n",
    "        print(f\"File moved to processed folder: {processed_path}\")\n",
    "\n",
    "        # Log success\n",
    "        success_log.append(video_file)\n",
    "        logging.info(f\"Successfully processed {video_file}\")\n",
    "        print(f\"Successfully processed {video_file}\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        error_message = f\"FFmpeg error for {video_file}: {e}\"\n",
    "        print(error_message)\n",
    "        error_log.append((video_file, error_message))\n",
    "        logging.error(error_message)\n",
    "    except Exception as e:\n",
    "        error_message = f\"General error for {video_file}: {e}\"\n",
    "        print(error_message)\n",
    "        error_log.append((video_file, error_message))\n",
    "        logging.error(error_message)\n",
    "\n",
    "# Perform folder parity check\n",
    "def get_file_bases(folder):\n",
    "    return {os.path.splitext(f)[0] for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))}\n",
    "\n",
    "videos = get_file_bases(processed_folder)\n",
    "audios = get_file_bases(audio_folder)\n",
    "texts = get_file_bases(text_folder)\n",
    "\n",
    "all_match = videos == audios == texts\n",
    "\n",
    "# Generate completion report\n",
    "report = \"Processing Report\\n\"\n",
    "report += f\"\\nSuccessfully Processed Files ({len(success_log)}):\\n\"\n",
    "report += \"\\n\".join(success_log)\n",
    "\n",
    "report += f\"\\n\\nSkipped Files ({len(skipped_log)}):\\n\"\n",
    "report += \"\\n\".join([f\"{file} - {reason}\" for file, reason in skipped_log])\n",
    "\n",
    "report += f\"\\n\\nErrors ({len(error_log)}):\\n\"\n",
    "report += \"\\n\".join([f\"{file} - {reason}\" for file, reason in error_log])\n",
    "\n",
    "report += f\"\\n\\nFolder Parity Check:\\n\"\n",
    "report += f\"All folders have matching files: {'Yes' if all_match else 'No'}\\n\"\n",
    "report += f\"Processed Videos: {len(videos)}\\n\"\n",
    "report += f\"Audio Files: {len(audios)}\\n\"\n",
    "report += f\"Text Files: {len(texts)}\\n\"\n",
    "\n",
    "# Save the report\n",
    "report_path = os.path.join(rootFolder, \"processing_report.txt\")\n",
    "with open(report_path, \"w\") as f:\n",
    "    f.write(report)\n",
    "\n",
    "# Display completion report\n",
    "print(report)\n",
    "\n",
    "csv_path = os.path.join(rootFolder, \"processing_log.csv\")\n",
    "file_exists = os.path.isfile(csv_path)\n",
    "\n",
    "# We'll store a timestamp for each run and each file processed/skipped/error\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "with open(csv_path, \"a\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # If file doesn't exist, write header\n",
    "    if not file_exists:\n",
    "        writer.writerow([\"Timestamp\", \"FileName\", \"Status\", \"Notes\"])\n",
    "\n",
    "    # Append rows for each processed file\n",
    "    for fname in success_log:\n",
    "        writer.writerow([current_time, fname, \"Processed\", \"\"])\n",
    "\n",
    "    # Append rows for each skipped file\n",
    "    for (fname, reason) in skipped_log:\n",
    "        writer.writerow([current_time, fname, \"Skipped\", reason])\n",
    "\n",
    "    # Append rows for each error file\n",
    "    for (fname, reason) in error_log:\n",
    "        writer.writerow([current_time, fname, \"Error\", reason])\n",
    "\n",
    "print(\"\\nCurrent CSV log entries:\")\n",
    "with open(csv_path, \"r\", encoding=\"utf-8\") as csvfile:\n",
    "    print(csvfile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OCvv85Y_u8V7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuClass": "premium",
   "gpuType": "A100",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "jupytext": {
   "formats": "ipynb,py:percent",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
