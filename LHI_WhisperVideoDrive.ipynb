{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LifeHackInnovationsLLC/whisper-video-transcription/blob/main/LHI_WhisperVideoDrive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "857e207c",
        "lines_to_next_cell": 0,
        "ExecuteTime": {
          "end_time": "2024-12-19T19:47:20.818961Z",
          "start_time": "2024-12-19T19:47:20.816042Z"
        }
      },
      "source": [
        "# LHI_WhisperVideoDrive.py"
      ],
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f90aaf4f",
        "ExecuteTime": {
          "end_time": "2024-12-19T19:47:20.842788Z",
          "start_time": "2024-12-19T19:47:20.840843Z"
        }
      },
      "source": [
        "# ---\n",
        "# jupyter:\n",
        "#   jupytext:\n",
        "#     formats: ipynb,py:percent\n",
        "#     text_representation:\n",
        "#       extension: .py\n",
        "#       format_name: percent\n",
        "#       format_version: '1.3'\n",
        "#       jupytext_version: 1.16.5\n",
        "#   kernelspec:\n",
        "#     display_name: Python 3\n",
        "#     name: python3\n",
        "# ---"
      ],
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LifeHackInnovationsLLC/whisper-video-transcription/blob/main/LHI_WhisperVideoDrive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f7b404b",
        "lines_to_next_cell": 2
      },
      "source": [
        "### Jupytext Initialization (Sync Logic)\n",
        "Ensure Jupytext is installed and the notebook is paired with the `.py` file.\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def ensure_module(module_name, install_name=None):\n",
        "    \"\"\"Install a module if it's not already installed.\"\"\"\n",
        "    try:\n",
        "        __import__(module_name)\n",
        "        print(f\"Module '{module_name}' is already installed.\")\n",
        "    except ImportError:\n",
        "        install_name = install_name or module_name\n",
        "        print(f\"Module '{module_name}' not found. Installing...\")\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", install_name], check=True)\n",
        "\n",
        "Ensure Jupytext is installed\n",
        "ensure_module(\"jupytext\")\n",
        "\n",
        "Sync the notebook with its paired `.py` file\n",
        "try:\n",
        "    subprocess.run([\"jupytext\", \"--sync\", \"LHI_WhisperVideoDrive.ipynb\"], check=True)\n",
        "    print(\"Jupytext synchronization successful.\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Error during Jupytext synchronization: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e425e731",
        "outputId": "49675703-4c7a-4883-d158-1f31724adbcd",
        "title": "Ensure required modules are installed and imported",
        "ExecuteTime": {
          "end_time": "2024-12-19T19:47:22.764736Z",
          "start_time": "2024-12-19T19:47:20.852652Z"
        }
      },
      "source": [
        "# Handle missing modules and Google Colab environment checks\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "\n",
        "# Install and import required modules\n",
        "required_modules = {\n",
        "    \"google.colab\": \"google-colab\",\n",
        "    \"whisper\": \"openai-whisper\",\n",
        "    \"librosa\": \"librosa\",\n",
        "    \"soundfile\": \"soundfile\",\n",
        "    \"colorama\": \"colorama\",\n",
        "    \"google-api-python-client\": \"google-api-python-client\",\n",
        "    \"google-auth-httplib2\": \"google-auth-httplib2\",\n",
        "    \"google-auth-oauthlib\": \"google-auth-oauthlib\"\n",
        "}\n",
        "\n",
        "\n",
        "for module, install_name in required_modules.items():\n",
        "    try:\n",
        "        __import__(module)\n",
        "        print(f\"Module '{module}' is already installed.\")\n",
        "    except ImportError:\n",
        "        print(f\"Module '{module}' not found. Installing...\")\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", install_name], check=True)\n",
        "\n",
        "# Conditional import for Google Colab\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    print(\"Google Colab environment detected.\")\n",
        "except ImportError:\n",
        "    print(\"Google Colab environment not detected. Skipping Colab imports.\")\n",
        "\n",
        "# Import other required modules\n",
        "import whisper\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Module 'google.colab' is already installed.\n",
            "Module 'whisper' is already installed.\n",
            "Module 'librosa' is already installed.\n",
            "Module 'soundfile' is already installed.\n",
            "Module 'colorama' is already installed.\n",
            "Module 'google-api-python-client' not found. Installing...\n",
            "Module 'google-auth-httplib2' not found. Installing...\n",
            "Module 'google-auth-oauthlib' not found. Installing...\n",
            "Google Colab environment detected.\n"
          ]
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z6Z6Z6ePz1R"
      },
      "source": [
        "\n",
        "#📼 OpenAI Whisper + Google Drive Video Transcription\n",
        "\n",
        "📺 Getting started video: https://youtu.be/YGpYinji7II\n",
        "\n",
        "###This application will extract audio from all the video files in a Google Drive folder and create a high-quality transcription with OpenAI's Whisper automatic speech recognition system.\n",
        "\n",
        "*Note: This requires giving the application permission to connect to your drive. Only you will have access to the contents of your drive, but please read the warnings carefully.*\n",
        "\n",
        "This notebook application:\n",
        "1. Connects to your Google Drive when you give it permission.\n",
        "2. Creates a WhisperVideo folder and three subfolders (ProcessedVideo, AudioFiles and TextFiles.)\n",
        "3. When you run the application it will search for all the video files (.mp4, .mov, mkv and .avi) in your WhisperVideo folder, transcribe them and then move the file to WhisperVideo/ProcessedVideo and save the transcripts to WhisperVideo/TextFiles. It will also add a copy of the new audio file to WhisperVideo/AudioFiles\n",
        "\n",
        "###**For faster performance set your runtime to \"GPU\"**\n",
        "*Click on \"Runtime\" in the menu and click \"Change runtime type\". Select \"GPU\".*\n",
        "\n",
        "\n",
        "**Note: If you add a new file after running this application you'll need to remount the drive in step 1 to make them searchable**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHhCHnaeTYw8"
      },
      "source": [
        "##0. Choose which 'LHI Client' or folder to add transcriptions to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L20Y96kiPz1R",
        "lines_to_next_cell": 2,
        "outputId": "d5a66c93-0445-4a56-d62c-9b819d3701d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking /content/drive status...\n",
            "Mount directory exists. Checking contents...\n",
            "Mountpoint already contains files. Attempting to unmount...\n",
            "Unmounted successfully or already unmounted.\n",
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully.\n",
            "Drive is mounted and ready.\n",
            "Proceeding...\n",
            "Initializing Google Drive API using OAuth (User Credentials)...\n",
            "Google Drive API service initialized successfully as the user.\n",
            "Select a client folder:\n",
            "1: WCBradley\n",
            "2: SiriusXM\n",
            "3: LHI\n",
            "4: Enter a custom folder path\n",
            "Enter the number corresponding to your choice (default: 1): 1\n",
            "Checking folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/\n",
            "Folder already exists: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/\n",
            "Checking folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/\n",
            "Folder already exists: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/\n",
            "Checking folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/\n",
            "Folder already exists: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/\n",
            "Checking folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/\n",
            "Folder already exists: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/\n",
            "WhisperVideo folder and subfolders initialized for client:\n",
            "WhisperVideo folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/\n",
            "Audio files folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/\n",
            "Text files folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/\n",
            "Processed videos folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/\n",
            "Folder 'Clients' found with ID: 1-ScYf1ZUli-IlejZbhFQPAHR3aBg_Tc5\n",
            "Folder 'WCBradley' found with ID: 17bG1M0aTeKQkELTrOQEAnXVX9U5wabFY\n",
            "Folder 'Videos' found with ID: 1hRUpMbXitI-Ms_actXqA8eiB0z3Nqrhv\n",
            "Folder 'WhisperVideo' found with ID: 10VXO4dTg36YySueayLgiAvzeC5dX5fNF\n",
            "Folder 'AudioFiles' found with ID: 1lUkZiBzqeBCaso5FD8KoEKYVHWmg2_Jl\n",
            "Folder 'TextFiles' found with ID: 1-1fP64TC2rzjrX0JA8CToJNi97l6h97F\n",
            "Folder 'ProcessedVideo' found with ID: 1-0yVKJTU6KTNCPWz20ojPQ3gDlyvGjFc\n",
            "=== REGISTRY TABLE ===\n",
            "╒════════╤════════════════╤══════════════════════════════════════════════════════════════════════════════╤═══════════════════════════════════╤══════════════════════════════════════════════════════════════════════════╕\n",
            "│ Type   │ Name           │ Path                                                                         │ ID                                │ URL                                                                      │\n",
            "╞════════╪════════════════╪══════════════════════════════════════════════════════════════════════════════╪═══════════════════════════════════╪══════════════════════════════════════════════════════════════════════════╡\n",
            "│ folder │ WhisperVideo   │ /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/                │ 10VXO4dTg36YySueayLgiAvzeC5dX5fNF │ https://drive.google.com/drive/folders/10VXO4dTg36YySueayLgiAvzeC5dX5fNF │\n",
            "├────────┼────────────────┼──────────────────────────────────────────────────────────────────────────────┼───────────────────────────────────┼──────────────────────────────────────────────────────────────────────────┤\n",
            "│ folder │ AudioFiles     │ /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/     │ 1lUkZiBzqeBCaso5FD8KoEKYVHWmg2_Jl │ https://drive.google.com/drive/folders/1lUkZiBzqeBCaso5FD8KoEKYVHWmg2_Jl │\n",
            "├────────┼────────────────┼──────────────────────────────────────────────────────────────────────────────┼───────────────────────────────────┼──────────────────────────────────────────────────────────────────────────┤\n",
            "│ folder │ TextFiles      │ /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/      │ 1-1fP64TC2rzjrX0JA8CToJNi97l6h97F │ https://drive.google.com/drive/folders/1-1fP64TC2rzjrX0JA8CToJNi97l6h97F │\n",
            "├────────┼────────────────┼──────────────────────────────────────────────────────────────────────────────┼───────────────────────────────────┼──────────────────────────────────────────────────────────────────────────┤\n",
            "│ folder │ ProcessedVideo │ /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/ │ 1-0yVKJTU6KTNCPWz20ojPQ3gDlyvGjFc │ https://drive.google.com/drive/folders/1-0yVKJTU6KTNCPWz20ojPQ3gDlyvGjFc │\n",
            "╘════════╧════════════════╧══════════════════════════════════════════════════════════════════════════════╧═══════════════════════════════════╧══════════════════════════════════════════════════════════════════════════╛\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "from colorama import Fore, Style, init\n",
        "from google.colab import drive\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from tabulate import tabulate\n",
        "\n",
        "\n",
        "init(autoreset=True)\n",
        "\n",
        "# Global registry\n",
        "registry_entries = []\n",
        "\n",
        "def add_to_registry(entry_type, name, path, entity_id=None, is_file=False):\n",
        "    \"\"\"Add or update an entity in the registry.\"\"\"\n",
        "    url = None\n",
        "    if entity_id:\n",
        "        if is_file:\n",
        "            url = f\"https://drive.google.com/file/d/{entity_id}/view\"\n",
        "        else:\n",
        "            url = f\"https://drive.google.com/drive/folders/{entity_id}\"\n",
        "\n",
        "    # Update or add\n",
        "    for e in registry_entries:\n",
        "        if e[\"path\"] == path:\n",
        "            e[\"type\"] = entry_type\n",
        "            e[\"name\"] = name\n",
        "            e[\"id\"] = entity_id\n",
        "            e[\"url\"] = url if url else e[\"url\"]\n",
        "            return\n",
        "\n",
        "    registry_entries.append({\n",
        "        \"type\": entry_type,\n",
        "        \"name\": name,\n",
        "        \"path\": path,\n",
        "        \"id\": entity_id,\n",
        "        \"url\": url\n",
        "    })\n",
        "\n",
        "def print_registry_table():\n",
        "    \"\"\"Print a table of all registered entries.\"\"\"\n",
        "    headers = [\"Type\", \"Name\", \"Path\", \"ID\", \"URL\"]\n",
        "    table_data = []\n",
        "    for e in registry_entries:\n",
        "        table_data.append([\n",
        "            e[\"type\"],\n",
        "            e[\"name\"],\n",
        "            e[\"path\"],\n",
        "            e[\"id\"] if e[\"id\"] else \"-\",\n",
        "            e[\"url\"] if e[\"url\"] else \"-\"\n",
        "        ])\n",
        "    print(Fore.CYAN + \"=== REGISTRY TABLE ===\")\n",
        "    print(tabulate(table_data, headers=headers, tablefmt=\"fancy_grid\"))\n",
        "\n",
        "def check_and_mount_drive():\n",
        "    print(\"Checking /content/drive status...\")\n",
        "    if os.path.exists(\"/content/drive\"):\n",
        "        print(\"Mount directory exists. Checking contents...\")\n",
        "        if os.listdir(\"/content/drive\"):\n",
        "            print(\"Mountpoint already contains files. Attempting to unmount...\")\n",
        "            print(\"Unmounted successfully or already unmounted.\")\n",
        "\n",
        "    # Mount Google Drive\n",
        "    print(\"Mounting Google Drive...\")\n",
        "    drive.mount(\"/content/drive\", force_remount=True)\n",
        "    print(\"Google Drive mounted successfully.\")\n",
        "\n",
        "    # Verify mount\n",
        "    if os.path.exists(\"/content/drive/MyDrive\"):\n",
        "        print(\"Drive is mounted and ready.\")\n",
        "        return True\n",
        "    else:\n",
        "        print(\"Mounting seems incomplete. Please check your drive configuration.\")\n",
        "        return False\n",
        "\n",
        "def initialize_drive_api():\n",
        "    \"\"\"\n",
        "    Initialize Google Drive API using OAuth user credentials.\n",
        "    This will prompt for user authentication.\n",
        "    \"\"\"\n",
        "    print(Fore.CYAN + \"Initializing Google Drive API using OAuth (User Credentials)...\")\n",
        "    try:\n",
        "        auth.authenticate_user()  # This will prompt you to authorize the app\n",
        "        service = build(\"drive\", \"v3\")\n",
        "        print(Fore.GREEN + \"Google Drive API service initialized successfully as the user.\")\n",
        "        return service\n",
        "    except Exception as e:\n",
        "        print(Fore.RED + f\"Failed to initialize Google Drive API: {e}\")\n",
        "        return None\n",
        "\n",
        "drive_service = initialize_drive_api()\n",
        "\n",
        "\n",
        "def get_file_id(file_name, folder_id):\n",
        "    \"\"\"\n",
        "    Retrieve the file ID for a given file name in a specific folder on Google Drive.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        results = drive_service.files().list(\n",
        "            q=f\"name='{file_name}' and '{folder_id}' in parents\",\n",
        "            spaces=\"drive\",\n",
        "            fields=\"files(id, name)\",\n",
        "            pageSize=1\n",
        "        ).execute()\n",
        "        items = results.get(\"files\", [])\n",
        "        if items:\n",
        "            return items[0][\"id\"]\n",
        "        else:\n",
        "            print(Fore.YELLOW + f\"File '{file_name}' not found in folder {folder_id}.\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(Fore.RED + f\"Error retrieving file ID for '{file_name}': {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def get_or_create_folder(drive_service, folder_name, parent_id):\n",
        "    \"\"\"\n",
        "    Retrieve or create a folder in Google Drive given a name and parent folder ID.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        query = f\"name='{folder_name}' and mimeType='application/vnd.google-apps.folder' and '{parent_id}' in parents\"\n",
        "        results = drive_service.files().list(\n",
        "            q=query,\n",
        "            spaces=\"drive\",\n",
        "            fields=\"files(id, name)\",\n",
        "            pageSize=1\n",
        "        ).execute()\n",
        "        items = results.get(\"files\", [])\n",
        "\n",
        "        if items:\n",
        "            folder_id = items[0][\"id\"]\n",
        "            print(Fore.GREEN + f\"Folder '{folder_name}' found with ID: {folder_id}\")\n",
        "            return folder_id\n",
        "        else:\n",
        "            folder_metadata = {\n",
        "                \"name\": folder_name,\n",
        "                \"mimeType\": \"application/vnd.google-apps.folder\",\n",
        "                \"parents\": [parent_id]\n",
        "            }\n",
        "            folder = drive_service.files().create(body=folder_metadata, fields=\"id\").execute()\n",
        "            folder_id = folder.get(\"id\")\n",
        "            print(Fore.GREEN + f\"Folder '{folder_name}' created with ID: {folder_id}\")\n",
        "            return folder_id\n",
        "    except Exception as e:\n",
        "        print(Fore.RED + f\"Error creating or retrieving folder '{folder_name}': {e}\")\n",
        "        return None\n",
        "\n",
        "folder_id_cache = {}\n",
        "\n",
        "def get_folder_id_from_path(drive_service, local_path):\n",
        "    if local_path in folder_id_cache:\n",
        "        return folder_id_cache[local_path]\n",
        "\n",
        "    prefix = \"/content/drive/MyDrive/\"\n",
        "    if not local_path.startswith(prefix):\n",
        "        print(Fore.RED + \"The path does not start with /content/drive/MyDrive/.\")\n",
        "        return None\n",
        "\n",
        "    relative_path = local_path[len(prefix):].strip(\"/\")\n",
        "    if not relative_path:\n",
        "        folder_id_cache[local_path] = \"root\"\n",
        "        return \"root\"\n",
        "\n",
        "    parts = relative_path.split(\"/\")\n",
        "    current_parent_id = \"root\"\n",
        "    for part in parts:\n",
        "        folder_id = get_or_create_folder(drive_service, part, current_parent_id)\n",
        "        if not folder_id:\n",
        "            print(Fore.RED + f\"Failed to navigate/create the folder for part: {part}\")\n",
        "            return None\n",
        "        current_parent_id = folder_id\n",
        "\n",
        "    # Cache the final folder ID\n",
        "    folder_id_cache[local_path] = current_parent_id\n",
        "    return current_parent_id\n",
        "\n",
        "\n",
        "# Attempt to check and mount the drive\n",
        "if check_and_mount_drive():\n",
        "    print(\"Proceeding...\")\n",
        "else:\n",
        "    print(\"Drive mount failed. Exiting.\")\n",
        "    raise SystemExit(\"Drive mount failed.\")\n",
        "\n",
        "drive_service = initialize_drive_api()\n",
        "\n",
        "# Predefined options for client folders\n",
        "clients = {\n",
        "    \"1\": \"/content/drive/MyDrive/Clients/WCBradley/Videos/\",\n",
        "    \"2\": \"/content/drive/MyDrive/Clients/SiriusXM/Videos/\",\n",
        "    \"3\": \"/content/drive/MyDrive/Clients/LHI/Videos/\"\n",
        "}\n",
        "\n",
        "print(\"Select a client folder:\")\n",
        "print(\"1: WCBradley\")\n",
        "print(\"2: SiriusXM\")\n",
        "print(\"3: LHI\")\n",
        "print(\"4: Enter a custom folder path\")\n",
        "\n",
        "choice = input(\"Enter the number corresponding to your choice (default: 1): \").strip()\n",
        "if choice in clients:\n",
        "    client_videos_folder = clients[choice]\n",
        "elif choice == \"4\":\n",
        "    client_videos_folder = input(\"Enter the full path to your Videos folder: \").strip()\n",
        "else:\n",
        "    client_videos_folder = clients[\"1\"]\n",
        "\n",
        "rootFolder = client_videos_folder + \"WhisperVideo/\"\n",
        "audio_folder = rootFolder + \"AudioFiles/\"\n",
        "text_folder = rootFolder + \"TextFiles/\"\n",
        "processed_folder = rootFolder + \"ProcessedVideo/\"\n",
        "\n",
        "# Ensure local folders exist\n",
        "folders = [rootFolder, audio_folder, text_folder, processed_folder]\n",
        "for folder in folders:\n",
        "    try:\n",
        "        print(f\"Checking folder: {folder}\")\n",
        "        folder_name = os.path.basename(os.path.normpath(folder))\n",
        "        if not os.path.exists(folder):\n",
        "            os.makedirs(folder)\n",
        "            print(Fore.GREEN + f\"Created folder: {folder}\")\n",
        "        else:\n",
        "            print(Fore.GREEN + f\"Folder already exists: {folder}\")\n",
        "        # Register locally. No ID yet.\n",
        "        add_to_registry(\"folder\", folder_name, folder)\n",
        "    except Exception as e:\n",
        "        print(Fore.RED + f\"Error ensuring folder {folder}: {e}\")\n",
        "\n",
        "print(Fore.CYAN + f\"WhisperVideo folder and subfolders initialized for client:\")\n",
        "print(Fore.GREEN + f\"WhisperVideo folder: {rootFolder}\")\n",
        "print(Fore.GREEN + f\"Audio files folder: {audio_folder}\")\n",
        "print(Fore.GREEN + f\"Text files folder: {text_folder}\")\n",
        "print(Fore.GREEN + f\"Processed videos folder: {processed_folder}\")\n",
        "\n",
        "# Now get or create these folders in Google Drive to get their IDs\n",
        "if drive_service:\n",
        "    rootFolderID = get_folder_id_from_path(drive_service, rootFolder)\n",
        "    if rootFolderID:\n",
        "        root_name = os.path.basename(os.path.normpath(rootFolder))\n",
        "        add_to_registry(\"folder\", root_name, rootFolder, rootFolderID, is_file=False)\n",
        "\n",
        "    audio_name = os.path.basename(os.path.normpath(audio_folder))\n",
        "    text_name = os.path.basename(os.path.normpath(text_folder))\n",
        "    processed_name = os.path.basename(os.path.normpath(processed_folder))\n",
        "\n",
        "    audio_id = get_or_create_folder(drive_service, audio_name, rootFolderID)\n",
        "    if audio_id:\n",
        "        add_to_registry(\"folder\", audio_name, audio_folder, audio_id, is_file=False)\n",
        "\n",
        "    text_id = get_or_create_folder(drive_service, text_name, rootFolderID)\n",
        "    if text_id:\n",
        "        add_to_registry(\"folder\", text_name, text_folder, text_id, is_file=False)\n",
        "\n",
        "    processed_id = get_or_create_folder(drive_service, processed_name, rootFolderID)\n",
        "    if processed_id:\n",
        "        add_to_registry(\"folder\", processed_name, processed_folder, processed_id, is_file=False)\n",
        "\n",
        "# Print the updated registry table with IDs and URLs\n",
        "print_registry_table()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFx0mfr031aw"
      },
      "source": [
        "##1. Load the code libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PomTPiCR5ihc",
        "outputId": "723c7cb6-8a2f-40d6-8181-54c65e7a4d9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-9o734189\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-9o734189\n",
            "  Resolved https://github.com/openai/whisper.git to commit 90db0de1896c23cbfaf0c58bc2d30665f709f170\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (10.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.8.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper==20240930) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "54 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 54 not upgraded.\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.12.14)\n",
            "Requirement already satisfied: audioread in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!pip install librosa\n",
        "!pip install audioread\n",
        "\n",
        "import whisper\n",
        "import time\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import re\n",
        "import os\n",
        "\n",
        "# model = whisper.load_model(\"tiny.en\")\n",
        "model = whisper.load_model(\"base.en\")\n",
        "# model = whisper.load_model(\"small.en\") # load the small model\n",
        "# model = whisper.load_model(\"medium.en\")\n",
        "# model = whisper.load_model(\"large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1CG2ZQerihnV"
      },
      "outputs": [],
      "source": [
        "# from colorama import Fore, Style, init\n",
        "# from googleapiclient.discovery import build\n",
        "# from google.oauth2.service_account import Credentials  # Ensure this import is included\n",
        "# from google.colab import drive\n",
        "\n",
        "# print(Fore.CYAN + \"Attempting to mount Google Drive...\")\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "# print(Fore.GREEN + \"Google Drive mounted successfully.\")\n",
        "\n",
        "# # Initialize colorama for console color support\n",
        "# init(autoreset=True)\n",
        "# print(Fore.CYAN + \"Colorama initialized for console color support.\")\n",
        "\n",
        "# # Google Drive API setup\n",
        "# def initialize_drive_api():\n",
        "#     \"\"\"\n",
        "#     Initialize Google Drive API service account for generating shareable links.\n",
        "#     \"\"\"\n",
        "#     print(Fore.CYAN + \"Initializing Google Drive API...\")\n",
        "#     try:\n",
        "#         credentials = Credentials.from_service_account_file(\n",
        "#             \"/content/drive/MyDrive/key.json\",\n",
        "#             scopes=[\"https://www.googleapis.com/auth/drive\"]\n",
        "#         )\n",
        "#         service = build(\"drive\", \"v3\", credentials=credentials)\n",
        "#         print(Fore.GREEN + \"Google Drive API service initialized successfully.\")\n",
        "#         return service\n",
        "#     except Exception as e:\n",
        "#         print(Fore.RED + f\"Failed to initialize Google Drive API: {e}\")\n",
        "#         return None\n",
        "\n",
        "# drive_service = initialize_drive_api()\n",
        "\n",
        "# def get_file_id(file_name, folder_id):\n",
        "#     \"\"\"\n",
        "#     Retrieve the file ID for a given file name in a specific folder on Google Drive.\n",
        "#     \"\"\"\n",
        "#     print(Fore.CYAN + f\"Searching for file '{file_name}' in folder ID '{folder_id}'...\")\n",
        "#     if drive_service is None:\n",
        "#         print(Fore.RED + \"Drive service not initialized. Cannot proceed.\")\n",
        "#         return None\n",
        "#     try:\n",
        "#         results = drive_service.files().list(\n",
        "#             q=f\"name='{file_name}' and '{folder_id}' in parents\",\n",
        "#             spaces=\"drive\",\n",
        "#             fields=\"files(id, name)\",\n",
        "#             pageSize=1\n",
        "#         ).execute()\n",
        "#         items = results.get(\"files\", [])\n",
        "#         if items:\n",
        "#             file_id = items[0][\"id\"]\n",
        "#             print(Fore.GREEN + f\"File '{file_name}' found with ID: {file_id}\")\n",
        "#             return file_id\n",
        "#         else:\n",
        "#             print(Fore.YELLOW + f\"File '{file_name}' not found in folder {folder_id}.\")\n",
        "#             return None\n",
        "#     except Exception as e:\n",
        "#         print(Fore.RED + f\"Error retrieving file ID for '{file_name}': {e}\")\n",
        "#         return None\n",
        "\n",
        "# def generate_shareable_link(file_id):\n",
        "#     \"\"\"\n",
        "#     Generate a shareable link for a given Google Drive file.\n",
        "#     \"\"\"\n",
        "#     print(Fore.CYAN + f\"Generating shareable link for file ID: {file_id}...\")\n",
        "#     if drive_service is None:\n",
        "#         print(Fore.RED + \"Drive service not initialized. Cannot generate link.\")\n",
        "#         return None\n",
        "#     try:\n",
        "#         permission = {\"type\": \"anyone\", \"role\": \"reader\"}\n",
        "#         drive_service.permissions().create(fileId=file_id, body=permission).execute()\n",
        "#         link = f\"https://drive.google.com/file/d/{file_id}/view\"\n",
        "#         print(Fore.GREEN + f\"Shareable link generated successfully: {link}\")\n",
        "#         return link\n",
        "#     except Exception as e:\n",
        "#         print(Fore.RED + f\"Failed to generate shareable link: {e}\")\n",
        "#         return None\n",
        "\n",
        "# # Example usage (uncomment to test):\n",
        "# # folder_id = \"YOUR_FOLDER_ID\"\n",
        "# # file_name = \"test.txt\"\n",
        "# # file_id = get_file_id(file_name, folder_id)\n",
        "# # if file_id:\n",
        "# #     link = generate_shareable_link(file_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIjETRxb5nuE"
      },
      "source": [
        "##2. Give the application permission to mount the drive and create the folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zxWvhDHzmspd",
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "# # Mount Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive\", force_remount=True)  # This will prompt for authorization.\n",
        "\n",
        "# import os\n",
        "\n",
        "# # Ensure WhisperVideo folder and its subfolders exist\n",
        "# folders = [rootFolder, audio_folder, text_folder, processed_folder]\n",
        "# for folder in folders:\n",
        "#     try:\n",
        "#         if not os.path.exists(folder):\n",
        "#             os.makedirs(folder)\n",
        "#             print(f\"Created folder: {folder}\")\n",
        "#         else:\n",
        "#             print(f\"Folder already exists: {folder}\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error ensuring folder {folder}: {e}\")\n",
        "\n",
        "# print(f\"All folders verified and ready under: {rootFolder}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fr8tBQy5Tvo"
      },
      "source": [
        "##3. Upload any video files you want transcribed in the \"WhisperVideo\" folder in your Google Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCef9V2i392e"
      },
      "source": [
        "## 4. Extract audio from the video files and create a transcription\n",
        "\n",
        "This step processes video files in the `WhisperVideo` folder by extracting audio, transcribing it, and saving the transcription in the `TextFiles` folder. The original video file is moved to the `ProcessedVideo` folder upon successful transcription.\n",
        "\n",
        "### Shareable Links\n",
        "The shareable link for the processed video is generated based on its Google Drive file path. This method avoids additional API calls and assumes that files are already shared within your team. The constructed link can be found at the beginning of the transcription file.\n",
        "\n",
        "Example of a shareable link format:\n",
        "```\n",
        "https://drive.google.com/file/d/<file_id>/view\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "D_rB5M99nmhw",
        "lines_to_next_cell": 2,
        "outputId": "7dfc5a9b-e941-4ed4-df15-e05c5e4fb95c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Audio directory: []\n",
            "Initial Text directory: []\n",
            "Initial Registry State:\n",
            "=== REGISTRY TABLE ===\n",
            "╒════════╤════════════════╤══════════════════════════════════════════════════════════════════════════════╤═══════════════════════════════════╤══════════════════════════════════════════════════════════════════════════╕\n",
            "│ Type   │ Name           │ Path                                                                         │ ID                                │ URL                                                                      │\n",
            "╞════════╪════════════════╪══════════════════════════════════════════════════════════════════════════════╪═══════════════════════════════════╪══════════════════════════════════════════════════════════════════════════╡\n",
            "│ folder │ WhisperVideo   │ /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/                │ 10VXO4dTg36YySueayLgiAvzeC5dX5fNF │ https://drive.google.com/drive/folders/10VXO4dTg36YySueayLgiAvzeC5dX5fNF │\n",
            "├────────┼────────────────┼──────────────────────────────────────────────────────────────────────────────┼───────────────────────────────────┼──────────────────────────────────────────────────────────────────────────┤\n",
            "│ folder │ AudioFiles     │ /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/     │ 1lUkZiBzqeBCaso5FD8KoEKYVHWmg2_Jl │ https://drive.google.com/drive/folders/1lUkZiBzqeBCaso5FD8KoEKYVHWmg2_Jl │\n",
            "├────────┼────────────────┼──────────────────────────────────────────────────────────────────────────────┼───────────────────────────────────┼──────────────────────────────────────────────────────────────────────────┤\n",
            "│ folder │ TextFiles      │ /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/      │ 1-1fP64TC2rzjrX0JA8CToJNi97l6h97F │ https://drive.google.com/drive/folders/1-1fP64TC2rzjrX0JA8CToJNi97l6h97F │\n",
            "├────────┼────────────────┼──────────────────────────────────────────────────────────────────────────────┼───────────────────────────────────┼──────────────────────────────────────────────────────────────────────────┤\n",
            "│ folder │ ProcessedVideo │ /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/ │ 1-0yVKJTU6KTNCPWz20ojPQ3gDlyvGjFc │ https://drive.google.com/drive/folders/1-0yVKJTU6KTNCPWz20ojPQ3gDlyvGjFc │\n",
            "╘════════╧════════════════╧══════════════════════════════════════════════════════════════════════════════╧═══════════════════════════════════╧══════════════════════════════════════════════════════════════════════════╛\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "get_file_id() missing 1 required positional argument: 'drive_service'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-05d7db70e751>\u001b[0m in \u001b[0;36m<cell line: 117>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0madd_to_registry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0mvideo_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_file_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrootFolderID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvideo_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mremove_from_registry_by_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: get_file_id() missing 1 required positional argument: 'drive_service'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "import logging\n",
        "import csv\n",
        "from datetime import datetime, timedelta\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import whisper\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "# Clear old local audio and text files before starting (Optional: do this if safe)\n",
        "for f in os.listdir(audio_folder):\n",
        "    if f.endswith(\".wav\"):\n",
        "        os.remove(os.path.join(audio_folder, f))\n",
        "for f in os.listdir(text_folder):\n",
        "    if f.endswith(\".txt\"):\n",
        "        os.remove(os.path.join(text_folder, f))\n",
        "\n",
        "# Also print directory states before processing\n",
        "print(\"Initial Audio directory:\", os.listdir(audio_folder))\n",
        "print(\"Initial Text directory:\", os.listdir(text_folder))\n",
        "\n",
        "def format_time(seconds):\n",
        "    return str(timedelta(seconds=int(seconds)))\n",
        "\n",
        "logging.basicConfig(\n",
        "    filename=\"processing_log.txt\",\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
        ")\n",
        "\n",
        "def remove_from_registry_by_path(path):\n",
        "    global registry_entries\n",
        "    registry_entries = [e for e in registry_entries if e[\"path\"] != path]\n",
        "\n",
        "def file_in_registry_with_id(path):\n",
        "    for e in registry_entries:\n",
        "        if e[\"path\"] == path and e.get(\"id\"):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def file_in_registry(path):\n",
        "    for e in registry_entries:\n",
        "        if e[\"path\"] == path:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def get_file_count(folder):\n",
        "    return len([f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))])\n",
        "\n",
        "def get_file_bases(folder):\n",
        "    return {os.path.splitext(f)[0] for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))}\n",
        "\n",
        "def verify_folder_state():\n",
        "    \"\"\"Compare local folder states with what we expect from processed videos.\"\"\"\n",
        "    videos = get_file_bases(processed_folder)\n",
        "    audios = get_file_bases(audio_folder)\n",
        "    texts = get_file_bases(text_folder)\n",
        "    all_match = (videos == audios == texts)\n",
        "\n",
        "    if not all_match:\n",
        "        print(\"WARNING: Folder parity mismatch detected:\")\n",
        "        print(f\"Processed Videos: {len(videos)} ({videos})\")\n",
        "        print(f\"Audio Files: {len(audios)} ({audios})\")\n",
        "        print(f\"Text Files: {len(texts)} ({texts})\")\n",
        "\n",
        "    return all_match\n",
        "\n",
        "def upload_file_to_drive(drive_service, file_path, parent_folder_id):\n",
        "    file_name = os.path.basename(file_path)\n",
        "    file_metadata = {\n",
        "        'name': file_name,\n",
        "        'parents': [parent_folder_id]\n",
        "    }\n",
        "    media = MediaFileUpload(file_path, resumable=True)\n",
        "    file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "    return file.get('id')\n",
        "\n",
        "def move_file_in_drive(drive_service, file_id, old_parent_id, new_parent_id):\n",
        "    file_info = drive_service.files().get(fileId=file_id, fields='parents').execute()\n",
        "    parents = file_info.get('parents', [])\n",
        "    if old_parent_id in parents:\n",
        "        parents.remove(old_parent_id)\n",
        "    updated_file = drive_service.files().update(\n",
        "        fileId=file_id,\n",
        "        addParents=new_parent_id,\n",
        "        removeParents=old_parent_id,\n",
        "        fields='id, parents'\n",
        "    ).execute()\n",
        "    return updated_file.get('id')\n",
        "\n",
        "def register_and_upload_local_file(drive_service, entry_type, file_name, file_path, parent_folder_id, is_file=True):\n",
        "    if file_in_registry_with_id(file_path):\n",
        "        # Already uploaded\n",
        "        return None, None\n",
        "    else:\n",
        "        if file_in_registry(file_path):\n",
        "            remove_from_registry_by_path(file_path)\n",
        "        add_to_registry(entry_type, file_name, file_path, entity_id=None, is_file=is_file)\n",
        "        file_id = upload_file_to_drive(drive_service, file_path, parent_folder_id)\n",
        "        if file_id:\n",
        "            link = generate_shareable_link(file_id)\n",
        "            remove_from_registry_by_path(file_path)\n",
        "            add_to_registry(entry_type, file_name, file_path, entity_id=file_id, is_file=is_file)\n",
        "            return file_id, link\n",
        "        else:\n",
        "            return None, None\n",
        "\n",
        "# Before processing videos, print registry and folder state\n",
        "print(\"Initial Registry State:\")\n",
        "print_registry_table()\n",
        "verify_folder_state()\n",
        "\n",
        "video_files = [f for f in os.listdir(rootFolder) if os.path.isfile(os.path.join(rootFolder, f))]\n",
        "\n",
        "for video_file in video_files:\n",
        "    if video_file == \"processing_report.txt\":\n",
        "        continue\n",
        "    if not video_file.lower().endswith((\".mp4\", \".mov\", \".avi\", \".mkv\")):\n",
        "        skipped_log.append((video_file, \"Invalid video format\"))\n",
        "        print(f\"Skipped {video_file}: Invalid video format.\")\n",
        "        continue\n",
        "\n",
        "    base_name = os.path.splitext(video_file)[0]\n",
        "    video_path = os.path.join(rootFolder, video_file)\n",
        "    audio_path = os.path.join(audio_folder, base_name + \".wav\")\n",
        "    text_path = os.path.join(text_folder, base_name + \".txt\")\n",
        "    processed_path = os.path.join(processed_folder, video_file)\n",
        "\n",
        "    if os.path.exists(processed_path):\n",
        "        print(f\"Video {video_file} already in processed folder. Skipping.\")\n",
        "        skipped_log.append((video_file, \"Already processed (video)\"))\n",
        "        continue\n",
        "\n",
        "    if not file_in_registry(video_path):\n",
        "        add_to_registry(\"file\", video_file, video_path, entity_id=None, is_file=True)\n",
        "\n",
        "    video_id = get_file_id(video_file, rootFolderID)\n",
        "    if video_id:\n",
        "        remove_from_registry_by_path(video_path)\n",
        "        add_to_registry(\"file\", video_file, video_path, entity_id=video_id, is_file=True)\n",
        "\n",
        "    # Log current folder state\n",
        "    print(f\"\\nProcessing {video_file}:\")\n",
        "    print(\"Audio directory:\", os.listdir(audio_folder))\n",
        "    print(\"Text directory:\", os.listdir(text_folder))\n",
        "\n",
        "    try:\n",
        "        if not os.path.exists(audio_path):\n",
        "            print(f\"Extracting audio for {video_file} to {audio_path}\")\n",
        "            try:\n",
        "                y, sr = librosa.load(video_path, sr=16000)\n",
        "                sf.write(audio_path, y, sr)\n",
        "                print(f\"Audio extraction successful using librosa for {video_file}\")\n",
        "            except Exception as e_librosa:\n",
        "                print(f\"Librosa extraction failed for {video_file}: {e_librosa}. Falling back to ffmpeg...\")\n",
        "                subprocess.run([\"ffmpeg\", \"-i\", video_path, \"-ar\", \"16000\", \"-ac\", \"1\", audio_path], check=True)\n",
        "                print(f\"Audio extraction successful using ffmpeg for {video_file}\")\n",
        "        else:\n",
        "            print(f\"Audio file {audio_path} already exists.\")\n",
        "\n",
        "        print(f\"Uploading audio file {os.path.basename(audio_path)}...\")\n",
        "        register_and_upload_local_file(drive_service, \"file\", os.path.basename(audio_path), audio_path, audio_folder_id, is_file=True)\n",
        "\n",
        "        if not os.path.exists(text_path):\n",
        "            print(f\"Starting transcription for {audio_path}\")\n",
        "            result = model.transcribe(audio_path)\n",
        "            print(f\"Transcription completed for {audio_path}\")\n",
        "\n",
        "            transcription_text = \"\"\n",
        "            for segment in result[\"segments\"]:\n",
        "                start_time = format_time(segment[\"start\"])\n",
        "                end_time = format_time(segment[\"end\"])\n",
        "                text_segment = segment[\"text\"].strip()\n",
        "                transcription_text += f\"[{start_time} - {end_time}] {text_segment}\\n\\n\"\n",
        "\n",
        "            print(f\"Saving transcription to {text_path}\")\n",
        "            with open(text_path, \"w\") as f:\n",
        "                f.write(transcription_text)\n",
        "        else:\n",
        "            print(f\"Text file {text_path} already exists.\")\n",
        "\n",
        "        print(f\"Uploading text file {os.path.basename(text_path)}...\")\n",
        "        register_and_upload_local_file(drive_service, \"file\", os.path.basename(text_path), text_path, text_folder_id, is_file=True)\n",
        "\n",
        "        print(f\"Moving file {video_file} to processed folder\")\n",
        "        shutil.move(video_path, processed_path)\n",
        "\n",
        "        if video_id:\n",
        "            move_file_in_drive(drive_service, video_id, rootFolderID, processed_folder_id)\n",
        "            remove_from_registry_by_path(video_path)\n",
        "            add_to_registry(\"file\", video_file, processed_path, entity_id=video_id, is_file=True)\n",
        "\n",
        "            for e in registry_entries:\n",
        "                if e[\"path\"] == processed_path and e[\"id\"] == video_id:\n",
        "                    if not e[\"url\"]:\n",
        "                        link = generate_shareable_link(video_id)\n",
        "                        remove_from_registry_by_path(processed_path)\n",
        "                        add_to_registry(\"file\", video_file, processed_path, entity_id=video_id, is_file=True)\n",
        "                    with open(text_path, \"a\") as f:\n",
        "                        f.write(f\"\\nOriginal Video Link: {e['url']}\\n\")\n",
        "                    break\n",
        "\n",
        "        print(\"Registry after processing this video:\")\n",
        "        print_registry_table()\n",
        "\n",
        "        if not verify_folder_state():\n",
        "            print(\"Folder parity mismatch after processing\", video_file)\n",
        "\n",
        "        success_log.append(video_file)\n",
        "        logging.info(f\"Successfully processed {video_file}\")\n",
        "\n",
        "    except subprocess.CalledProcessError as ffmpeg_error:\n",
        "        error_message = f\"FFmpeg error for {video_file}: {ffmpeg_error}\"\n",
        "        print(error_message)\n",
        "        error_log.append((video_file, error_message))\n",
        "        logging.error(error_message)\n",
        "\n",
        "    except Exception as general_error:\n",
        "        error_message = f\"General error for {video_file}: {general_error}\"\n",
        "        print(error_message)\n",
        "        error_log.append((video_file, error_message))\n",
        "        logging.error(error_message)\n",
        "\n",
        "# Final parity check\n",
        "videos = get_file_bases(processed_folder)\n",
        "audios = get_file_bases(audio_folder)\n",
        "texts = get_file_bases(text_folder)\n",
        "all_match = (videos == audios == texts)\n",
        "\n",
        "report = \"Processing Report\\n\"\n",
        "report += f\"\\nSuccessfully Processed Files ({len(success_log)}):\\n\"\n",
        "report += \"\\n\".join(success_log)\n",
        "report += f\"\\n\\nSkipped Files ({len(skipped_log)}):\\n\"\n",
        "report += \"\\n\".join([f\"{file} - {reason}\" for file, reason in skipped_log])\n",
        "report += f\"\\n\\nErrors ({len(error_log)}):\\n\"\n",
        "report += \"\\n\".join([f\"{file} - {reason}\" for file, reason in error_log])\n",
        "report += f\"\\n\\nFolder Parity Check:\\n\"\n",
        "report += f\"All folders have matching files: {'Yes' if all_match else 'No'}\\n\"\n",
        "report += f\"Processed Videos: {len(videos)}\\n\"\n",
        "report += f\"Audio Files: {len(audios)}\\n\"\n",
        "report += f\"Text Files: {len(texts)}\\n\"\n",
        "\n",
        "with open(os.path.join(rootFolder, \"processing_report.txt\"), \"w\") as f:\n",
        "    f.write(report)\n",
        "\n",
        "print(\"=== COMPLETION REPORT ===\")\n",
        "print(report)\n",
        "\n",
        "csv_path = os.path.join(rootFolder, \"processing_log.csv\")\n",
        "file_exists = os.path.isfile(csv_path)\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "with open(csv_path, \"a\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    if not file_exists:\n",
        "        writer.writerow([\"Timestamp\", \"FileName\", \"Status\", \"Notes\"])\n",
        "\n",
        "    for fname in success_log:\n",
        "        writer.writerow([current_time, fname, \"Processed\", \"\"])\n",
        "    for (fname, reason) in skipped_log:\n",
        "        writer.writerow([current_time, fname, \"Skipped\", reason])\n",
        "    for (fname, reason) in error_log:\n",
        "        writer.writerow([current_time, fname, \"Error\", reason])\n",
        "\n",
        "print(\"\\nCurrent CSV log entries:\")\n",
        "with open(csv_path, \"r\", encoding=\"utf-8\") as csvfile:\n",
        "    print(csvfile.read())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCvv85Y_u8V7"
      },
      "outputs": [],
      "source": [
        "# ### Final Note for Synchronization\n",
        "# For Colab: Sync changes manually after downloading the notebook.\n",
        "# For Local: Use the Jupytext command:\n",
        "#    jupytext --sync LHI_WhisperVideoDrive.ipynb\n",
        "\n",
        "print(\"Final Note: Synchronize your files locally using Jupytext.\")\n",
        "print(\"Colab users: Save your notebook and download it to sync manually.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuClass": "premium",
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "jupytext": {
      "formats": "ipynb,py:percent",
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "name": "python3",
      "language": "python"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}