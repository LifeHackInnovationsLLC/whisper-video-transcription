{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/LifeHackInnovationsLLC/whisper-video-transcription/blob/main/LHI_WhisperVideoDrive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "857e207c",
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# LHI_WhisperVideoDrive.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "f90aaf4f"
   },
   "outputs": [],
   "source": [
    "# ---\n",
    "# jupyter:\n",
    "#   jupytext:\n",
    "#     formats: ipynb,py:percent\n",
    "#     text_representation:\n",
    "#       extension: .py\n",
    "#       format_name: percent\n",
    "#       format_version: '1.3'\n",
    "#       jupytext_version: 1.16.5\n",
    "#   kernelspec:\n",
    "#     display_name: Python 3\n",
    "#     name: python3\n",
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/LifeHackInnovationsLLC/whisper-video-transcription/blob/main/LHI_WhisperVideoDrive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f7b404b",
    "lines_to_next_cell": 2
   },
   "source": [
    "### Jupytext Initialization (Sync Logic)\n",
    "Ensure Jupytext is installed and the notebook is paired with the `.py` file.\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def ensure_module(module_name, install_name=None):\n",
    "    \"\"\"Install a module if it's not already installed.\"\"\"\n",
    "    try:\n",
    "        __import__(module_name)\n",
    "        print(f\"Module '{module_name}' is already installed.\")\n",
    "    except ImportError:\n",
    "        install_name = install_name or module_name\n",
    "        print(f\"Module '{module_name}' not found. Installing...\")\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", install_name], check=True)\n",
    "\n",
    "Ensure Jupytext is installed\n",
    "ensure_module(\"jupytext\")\n",
    "\n",
    "Sync the notebook with its paired `.py` file\n",
    "try:\n",
    "    subprocess.run([\"jupytext\", \"--sync\", \"LHI_WhisperVideoDrive.ipynb\"], check=True)\n",
    "    print(\"Jupytext synchronization successful.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error during Jupytext synchronization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e425e731",
    "outputId": "88cd1d9d-3c68-4b7d-fef0-c21b5ce95d69",
    "title": "Ensure required modules are installed and imported"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module 'google.colab' is already installed.\n",
      "Module 'whisper' is already installed.\n",
      "Module 'librosa' is already installed.\n",
      "Module 'soundfile' is already installed.\n",
      "Google Colab environment detected.\n"
     ]
    }
   ],
   "source": [
    "# Handle missing modules and Google Colab environment checks\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "\n",
    "# Install and import required modules\n",
    "required_modules = {\n",
    "    \"google.colab\": \"google-colab\",\n",
    "    \"whisper\": \"openai-whisper\",\n",
    "    \"librosa\": \"librosa\",\n",
    "    \"soundfile\": \"soundfile\"\n",
    "}\n",
    "\n",
    "for module, install_name in required_modules.items():\n",
    "    try:\n",
    "        __import__(module)\n",
    "        print(f\"Module '{module}' is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"Module '{module}' not found. Installing...\")\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", install_name], check=True)\n",
    "\n",
    "# Conditional import for Google Colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    print(\"Google Colab environment detected.\")\n",
    "except ImportError:\n",
    "    print(\"Google Colab environment not detected. Skipping Colab imports.\")\n",
    "\n",
    "# Import other required modules\n",
    "import whisper\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Z6Z6Z6ePz1R"
   },
   "source": [
    "\n",
    "#ðŸ“¼ OpenAI Whisper + Google Drive Video Transcription\n",
    "\n",
    "ðŸ“º Getting started video: https://youtu.be/YGpYinji7II\n",
    "\n",
    "###This application will extract audio from all the video files in a Google Drive folder and create a high-quality transcription with OpenAI's Whisper automatic speech recognition system.\n",
    "\n",
    "*Note: This requires giving the application permission to connect to your drive. Only you will have access to the contents of your drive, but please read the warnings carefully.*\n",
    "\n",
    "This notebook application:\n",
    "1. Connects to your Google Drive when you give it permission.\n",
    "2. Creates a WhisperVideo folder and three subfolders (ProcessedVideo, AudioFiles and TextFiles.)\n",
    "3. When you run the application it will search for all the video files (.mp4, .mov, mkv and .avi) in your WhisperVideo folder, transcribe them and then move the file to WhisperVideo/ProcessedVideo and save the transcripts to WhisperVideo/TextFiles. It will also add a copy of the new audio file to WhisperVideo/AudioFiles\n",
    "\n",
    "###**For faster performance set your runtime to \"GPU\"**\n",
    "*Click on \"Runtime\" in the menu and click \"Change runtime type\". Select \"GPU\".*\n",
    "\n",
    "\n",
    "**Note: If you add a new file after running this application you'll need to remount the drive in step 1 to make them searchable**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHhCHnaeTYw8"
   },
   "source": [
    "##0. Choose which 'LHI Client' or folder to add transcriptions to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L20Y96kiPz1R",
    "lines_to_next_cell": 2,
    "outputId": "107d8e38-a154-4a66-9be5-05f49633104f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking /content/drive status...\n",
      "Mount directory exists. Checking contents...\n",
      "Mountpoint already contains files. Attempting to unmount...\n",
      "Unmounted successfully.\n",
      "Mounting Google Drive...\n",
      "Mounted at /content/drive\n",
      "Google Drive mounted successfully.\n",
      "Drive is mounted and ready.\n",
      "Proceeding with folder creation...\n",
      "Select a client folder:\n",
      "1: WCBradley\n",
      "2: SiriusXM\n",
      "3: LHI\n",
      "4: Enter a custom folder path\n",
      "Enter the number corresponding to your choice (default: 1): \n",
      "Checking folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/\n",
      "Folder already exists: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/\n",
      "Checking folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/\n",
      "Folder already exists: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/\n",
      "Checking folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/\n",
      "Folder already exists: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/\n",
      "Checking folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/\n",
      "Folder already exists: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/\n",
      "WhisperVideo folder and subfolders initialized for client:\n",
      "WhisperVideo folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/\n",
      "Audio files folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/\n",
      "Text files folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/\n",
      "Processed videos folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Reusable function to check and mount Google Drive\n",
    "def check_and_mount_drive():\n",
    "    print(\"Checking /content/drive status...\")\n",
    "    if os.path.exists(\"/content/drive\"):\n",
    "        print(\"Mount directory exists. Checking contents...\")\n",
    "        if os.listdir(\"/content/drive\"):\n",
    "            print(\"Mountpoint already contains files. Attempting to unmount...\")\n",
    "            try:\n",
    "                # Unmount the existing mountpoint\n",
    "                !fusermount -u /content/drive\n",
    "                print(\"Unmounted successfully.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to unmount: {e}\")\n",
    "                print(\"If the issue persists, please select 'Runtime > Disconnect and delete runtime' and try again.\")\n",
    "                return False\n",
    "\n",
    "    # Mount Google Drive\n",
    "    print(\"Mounting Google Drive...\")\n",
    "    from google.colab import drive\n",
    "    try:\n",
    "        drive.mount(\"/content/drive\", force_remount=True)\n",
    "        print(\"Google Drive mounted successfully.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Mounting failed: {e}\")\n",
    "        print(\"If the issue persists, please select 'Runtime > Disconnect and delete runtime' and try again.\")\n",
    "        return False\n",
    "\n",
    "    # Verify mount\n",
    "    if os.path.exists(\"/content/drive/MyDrive\"):\n",
    "        print(\"Drive is mounted and ready.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Mounting seems incomplete. Please check your drive configuration.\")\n",
    "        return False\n",
    "\n",
    "# Attempt to check and mount the drive\n",
    "if check_and_mount_drive():\n",
    "    print(\"Proceeding with folder creation...\")\n",
    "else:\n",
    "    print(\"Drive mount failed. Cannot proceed.\")\n",
    "    raise SystemExit(\"Drive mount failed. Exiting.\")\n",
    "\n",
    "# Predefined options for client folders\n",
    "clients = {\n",
    "    \"1\": \"/content/drive/MyDrive/Clients/WCBradley/Videos/\",\n",
    "    \"2\": \"/content/drive/MyDrive/Clients/SiriusXM/Videos/\",\n",
    "    \"3\": \"/content/drive/MyDrive/Clients/LHI/Videos/\"\n",
    "}\n",
    "\n",
    "# Display options to the user\n",
    "print(\"Select a client folder:\")\n",
    "print(\"1: WCBradley\")\n",
    "print(\"2: SiriusXM\")\n",
    "print(\"3: LHI\")\n",
    "print(\"4: Enter a custom folder path\")\n",
    "\n",
    "# Get user input\n",
    "choice = input(\"Enter the number corresponding to your choice (default: 1): \").strip()\n",
    "\n",
    "# Determine the root folder for the client\n",
    "if choice in clients:\n",
    "    client_videos_folder = clients[choice]\n",
    "elif choice == \"4\":\n",
    "    client_videos_folder = input(\"Enter the full path to your Videos folder: \").strip()\n",
    "else:\n",
    "    # Default to WCBradley if no valid input\n",
    "    client_videos_folder = clients[\"1\"]\n",
    "\n",
    "# Define the WhisperVideo root folder within the client's Videos folder\n",
    "rootFolder = client_videos_folder + \"WhisperVideo/\"\n",
    "\n",
    "# Define subfolder paths relative to the WhisperVideo root folder\n",
    "audio_folder = rootFolder + \"AudioFiles/\"\n",
    "text_folder = rootFolder + \"TextFiles/\"\n",
    "processed_folder = rootFolder + \"ProcessedVideo/\"\n",
    "\n",
    "# Ensure WhisperVideo folder and its subfolders exist\n",
    "folders = [rootFolder, audio_folder, text_folder, processed_folder]\n",
    "for folder in folders:\n",
    "    try:\n",
    "        print(f\"Checking folder: {folder}\")\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "            print(f\"Created folder: {folder}\")\n",
    "        else:\n",
    "            print(f\"Folder already exists: {folder}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error ensuring folder {folder}: {e}\")\n",
    "\n",
    "print(f\"WhisperVideo folder and subfolders initialized for client:\")\n",
    "print(f\"WhisperVideo folder: {rootFolder}\")\n",
    "print(f\"Audio files folder: {audio_folder}\")\n",
    "print(f\"Text files folder: {text_folder}\")\n",
    "print(f\"Processed videos folder: {processed_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFx0mfr031aw"
   },
   "source": [
    "##1. Load the code libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PomTPiCR5ihc",
    "outputId": "45a93879-07fa-4652-f974-abc3c4869ff2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-tui8lk5z\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-tui8lk5z\n",
      "  Resolved https://github.com/openai/whisper.git to commit 90db0de1896c23cbfaf0c58bc2d30665f709f170\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (1.26.4)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (2.5.1+cu121)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (4.66.6)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (10.5.0)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.8.0)\n",
      "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (3.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper==20240930) (3.16.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
      "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
      "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
      "Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
      "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
      "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
      "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
      "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "51 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n",
      "Requirement already satisfied: audioread in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git\n",
    "!sudo apt update && sudo apt install ffmpeg\n",
    "!pip install librosa\n",
    "!pip install audioread\n",
    "\n",
    "import whisper\n",
    "import time\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import re\n",
    "import os\n",
    "\n",
    "# model = whisper.load_model(\"tiny.en\")\n",
    "model = whisper.load_model(\"base.en\")\n",
    "# model = whisper.load_model(\"small.en\") # load the small model\n",
    "# model = whisper.load_model(\"medium.en\")\n",
    "# model = whisper.load_model(\"large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIjETRxb5nuE"
   },
   "source": [
    "##2. Give the application permission to mount the drive and create the folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "zxWvhDHzmspd",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# # Mount Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\", force_remount=True)  # This will prompt for authorization.\n",
    "\n",
    "# import os\n",
    "\n",
    "# # Ensure WhisperVideo folder and its subfolders exist\n",
    "# folders = [rootFolder, audio_folder, text_folder, processed_folder]\n",
    "# for folder in folders:\n",
    "#     try:\n",
    "#         if not os.path.exists(folder):\n",
    "#             os.makedirs(folder)\n",
    "#             print(f\"Created folder: {folder}\")\n",
    "#         else:\n",
    "#             print(f\"Folder already exists: {folder}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error ensuring folder {folder}: {e}\")\n",
    "\n",
    "# print(f\"All folders verified and ready under: {rootFolder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fr8tBQy5Tvo"
   },
   "source": [
    "##3. Upload any video files you want transcribed in the \"WhisperVideo\" folder in your Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCef9V2i392e"
   },
   "source": [
    "## 4. Extract audio from the video files and create a transcription\n",
    "\n",
    "This step processes video files in the `WhisperVideo` folder by extracting audio, transcribing it, and saving the transcription in the `TextFiles` folder. The original video file is moved to the `ProcessedVideo` folder upon successful transcription.\n",
    "\n",
    "### Shareable Links\n",
    "The shareable link for the processed video is generated based on its Google Drive file path. This method avoids additional API calls and assumes that files are already shared within your team. The constructed link can be found at the beginning of the transcription file.\n",
    "\n",
    "Example of a shareable link format:\n",
    "```\n",
    "https://drive.google.com/file/d/<file_id>/view\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D_rB5M99nmhw",
    "lines_to_next_cell": 2,
    "outputId": "e6c4a64f-83e9-49e7-d865-640da49a8a35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped processing_log.csv: Invalid format.\n",
      "Processing Report\n",
      "\n",
      "Successfully Processed Files (0):\n",
      "\n",
      "\n",
      "Skipped Files (1):\n",
      "processing_log.csv - Invalid format\n",
      "\n",
      "Errors (0):\n",
      "\n",
      "\n",
      "Folder Parity Check:\n",
      "All folders have matching files: Yes\n",
      "Processed Videos: 2\n",
      "Audio Files: 2\n",
      "Text Files: 2\n",
      "\n",
      "\n",
      "Current CSV log entries:\n",
      "Timestamp,FileName,Status,Notes\n",
      "2024-12-16 03:58:23,Second Standup.mov,Processed,\n",
      "2024-12-16 03:58:23,Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).mov,Processed,\n",
      "2024-12-16 04:02:22,processing_log.csv,Skipped,Invalid format\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datetime import timedelta\n",
    "import subprocess\n",
    "import logging\n",
    "import csv\n",
    "from datetime import datetime\n",
    "# Removed: from urllib.parse import quote\n",
    "\n",
    "# Helper function to format time\n",
    "def format_time(seconds):\n",
    "    \"\"\"Convert seconds to HH:MM:SS format.\"\"\"\n",
    "    return str(timedelta(seconds=int(seconds)))\n",
    "\n",
    "# Removed the generate_shareable_link function\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    filename=\"processing_log.txt\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "\n",
    "# Ensure folders are created\n",
    "folders = [rootFolder, audio_folder, text_folder, processed_folder]\n",
    "for folder in folders:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "# Initialize logs\n",
    "success_log = []\n",
    "error_log = []\n",
    "skipped_log = []\n",
    "\n",
    "# Process all video files in WhisperVideo folder\n",
    "video_files = [f for f in os.listdir(rootFolder) if os.path.isfile(os.path.join(rootFolder, f))]\n",
    "\n",
    "for video_file in video_files:\n",
    "    # Exclude the report file from processing\n",
    "    if video_file == \"processing_report.txt\":\n",
    "        continue\n",
    "\n",
    "    # Skip non-video files\n",
    "    if not video_file.endswith((\".mp4\", \".mov\", \".avi\", \".mkv\")):\n",
    "        skipped_log.append((video_file, \"Invalid format\"))\n",
    "        print(f\"Skipped {video_file}: Invalid format.\")\n",
    "        continue\n",
    "\n",
    "    # Define paths\n",
    "    video_path = os.path.join(rootFolder, video_file)\n",
    "    audio_path = os.path.join(audio_folder, video_file[:-4] + \".wav\")\n",
    "    text_path = os.path.join(text_folder, video_file[:-4] + \".txt\")\n",
    "    processed_path = os.path.join(processed_folder, video_file)\n",
    "\n",
    "    try:\n",
    "        print(f\"Extracting audio for {video_file} to {audio_path}\")\n",
    "        # Extract audio\n",
    "        try:\n",
    "            # Attempt to load the audio using librosa\n",
    "            y, sr = librosa.load(video_path, sr=16000)  # Load audio with 16 kHz sampling rate\n",
    "            sf.write(audio_path, y, sr)  # Save audio as a WAV file\n",
    "            print(f\"Audio extraction successful using librosa for {video_file}\")\n",
    "        except Exception as e_librosa:\n",
    "            print(f\"Librosa extraction failed for {video_file}: {e_librosa}\")\n",
    "            print(f\"Falling back to ffmpeg for {video_file}\")\n",
    "            # Use ffmpeg as a fallback\n",
    "            subprocess.run([\"ffmpeg\", \"-i\", video_path, \"-ar\", \"16000\", \"-ac\", \"1\", audio_path], check=True)\n",
    "            print(f\"Audio extraction successful using ffmpeg for {video_file}\")\n",
    "\n",
    "        print(f\"Starting transcription for {audio_path}\")\n",
    "        # Transcribe the audio using Whisper\n",
    "        result = model.transcribe(audio_path)\n",
    "        print(f\"Transcription completed for {audio_path}\")\n",
    "\n",
    "        # Create initial transcription\n",
    "        text = \"\"\n",
    "        for segment in result[\"segments\"]:\n",
    "            start_time = format_time(segment[\"start\"])\n",
    "            end_time = format_time(segment[\"end\"])\n",
    "            text_segment = segment[\"text\"].strip()\n",
    "            text += f\"[{start_time} - {end_time}] {text_segment}\\n\\n\"\n",
    "\n",
    "        print(f\"Saving transcription to {text_path}\")\n",
    "        # Save the transcription\n",
    "        with open(text_path, \"w\") as f:\n",
    "            f.write(text)\n",
    "        print(f\"Transcription saved successfully for {video_file}\")\n",
    "\n",
    "        print(f\"Moving file {video_file} to processed folder\")\n",
    "        # Move the video to ProcessedVideo folder\n",
    "        shutil.move(video_path, processed_path)\n",
    "        print(f\"File moved to processed folder: {processed_path}\")\n",
    "\n",
    "        # Log success\n",
    "        success_log.append(video_file)\n",
    "        logging.info(f\"Successfully processed {video_file}\")\n",
    "        print(f\"Successfully processed {video_file}\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        error_message = f\"FFmpeg error for {video_file}: {e}\"\n",
    "        print(error_message)\n",
    "        error_log.append((video_file, error_message))\n",
    "        logging.error(error_message)\n",
    "    except Exception as e:\n",
    "        error_message = f\"General error for {video_file}: {e}\"\n",
    "        print(error_message)\n",
    "        error_log.append((video_file, error_message))\n",
    "        logging.error(error_message)\n",
    "\n",
    "# Perform folder parity check\n",
    "def get_file_bases(folder):\n",
    "    return {os.path.splitext(f)[0] for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))}\n",
    "\n",
    "videos = get_file_bases(processed_folder)\n",
    "audios = get_file_bases(audio_folder)\n",
    "texts = get_file_bases(text_folder)\n",
    "\n",
    "all_match = videos == audios == texts\n",
    "\n",
    "# Generate completion report\n",
    "report = \"Processing Report\\n\"\n",
    "report += f\"\\nSuccessfully Processed Files ({len(success_log)}):\\n\"\n",
    "report += \"\\n\".join(success_log)\n",
    "\n",
    "report += f\"\\n\\nSkipped Files ({len(skipped_log)}):\\n\"\n",
    "report += \"\\n\".join([f\"{file} - {reason}\" for file, reason in skipped_log])\n",
    "\n",
    "report += f\"\\n\\nErrors ({len(error_log)}):\\n\"\n",
    "report += \"\\n\".join([f\"{file} - {reason}\" for file, reason in error_log])\n",
    "\n",
    "report += f\"\\n\\nFolder Parity Check:\\n\"\n",
    "report += f\"All folders have matching files: {'Yes' if all_match else 'No'}\\n\"\n",
    "report += f\"Processed Videos: {len(videos)}\\n\"\n",
    "report += f\"Audio Files: {len(audios)}\\n\"\n",
    "report += f\"Text Files: {len(texts)}\\n\"\n",
    "\n",
    "# Save the report\n",
    "report_path = os.path.join(rootFolder, \"processing_report.txt\")\n",
    "with open(report_path, \"w\") as f:\n",
    "    f.write(report)\n",
    "\n",
    "# Display completion report\n",
    "print(report)\n",
    "\n",
    "csv_path = os.path.join(rootFolder, \"processing_log.csv\")\n",
    "file_exists = os.path.isfile(csv_path)\n",
    "\n",
    "# We'll store a timestamp for each run and each file processed/skipped/error\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "with open(csv_path, \"a\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # If file doesn't exist, write header\n",
    "    if not file_exists:\n",
    "        writer.writerow([\"Timestamp\", \"FileName\", \"Status\", \"Notes\"])\n",
    "\n",
    "    # Append rows for each processed file\n",
    "    for fname in success_log:\n",
    "        writer.writerow([current_time, fname, \"Processed\", \"\"])\n",
    "\n",
    "    # Append rows for each skipped file\n",
    "    for (fname, reason) in skipped_log:\n",
    "        writer.writerow([current_time, fname, \"Skipped\", reason])\n",
    "\n",
    "    # Append rows for each error file\n",
    "    for (fname, reason) in error_log:\n",
    "        writer.writerow([current_time, fname, \"Error\", reason])\n",
    "\n",
    "print(\"\\nCurrent CSV log entries:\")\n",
    "with open(csv_path, \"r\", encoding=\"utf-8\") as csvfile:\n",
    "    print(csvfile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OCvv85Y_u8V7",
    "outputId": "e7b9b784-6cfd-42d4-e3a5-b0c2fdac1b05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupytext is already installed.\n",
      "Synchronizing notebook with 'LHI_WhisperVideoDrive.ipynb'...\n",
      "Error during Jupytext synchronization: Command '['/usr/bin/python3', '-m', 'jupytext', '--sync', 'LHI_WhisperVideoDrive.ipynb']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "# ### Final Note for Synchronization\n",
    "# For Colab: Sync changes manually after downloading the notebook.\n",
    "# For Local: Use the Jupytext command:\n",
    "#    jupytext --sync LHI_WhisperVideoDrive.ipynb\n",
    "\n",
    "print(\"Final Note: Synchronize your files locally using Jupytext.\")\n",
    "print(\"Colab users: Save your notebook and download it to sync manually.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuClass": "premium",
   "gpuType": "A100",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "jupytext": {
   "formats": "ipynb,py:percent",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
