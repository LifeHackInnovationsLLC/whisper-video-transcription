{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LifeHackInnovationsLLC/whisper-video-transcription/blob/main/LHI_WhisperVideoDrive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "857e207c",
        "lines_to_next_cell": 0,
        "ExecuteTime": {
          "end_time": "2024-12-19T19:47:20.818961Z",
          "start_time": "2024-12-19T19:47:20.816042Z"
        }
      },
      "source": [
        "# LHI_WhisperVideoDrive.py"
      ],
      "outputs": [],
      "execution_count": 57
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f90aaf4f",
        "ExecuteTime": {
          "end_time": "2024-12-19T19:47:20.842788Z",
          "start_time": "2024-12-19T19:47:20.840843Z"
        }
      },
      "source": [
        "# ---\n",
        "# jupyter:\n",
        "#   jupytext:\n",
        "#     formats: ipynb,py:percent\n",
        "#     text_representation:\n",
        "#       extension: .py\n",
        "#       format_name: percent\n",
        "#       format_version: '1.3'\n",
        "#       jupytext_version: 1.16.5\n",
        "#   kernelspec:\n",
        "#     display_name: Python 3\n",
        "#     name: python3\n",
        "# ---"
      ],
      "outputs": [],
      "execution_count": 58
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LifeHackInnovationsLLC/whisper-video-transcription/blob/main/LHI_WhisperVideoDrive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f7b404b",
        "lines_to_next_cell": 2
      },
      "source": [
        "### Jupytext Initialization (Sync Logic)\n",
        "Ensure Jupytext is installed and the notebook is paired with the `.py` file.\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def ensure_module(module_name, install_name=None):\n",
        "    \"\"\"Install a module if it's not already installed.\"\"\"\n",
        "    try:\n",
        "        __import__(module_name)\n",
        "        print(f\"Module '{module_name}' is already installed.\")\n",
        "    except ImportError:\n",
        "        install_name = install_name or module_name\n",
        "        print(f\"Module '{module_name}' not found. Installing...\")\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", install_name], check=True)\n",
        "\n",
        "Ensure Jupytext is installed\n",
        "ensure_module(\"jupytext\")\n",
        "\n",
        "Sync the notebook with its paired `.py` file\n",
        "try:\n",
        "    subprocess.run([\"jupytext\", \"--sync\", \"LHI_WhisperVideoDrive.ipynb\"], check=True)\n",
        "    print(\"Jupytext synchronization successful.\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Error during Jupytext synchronization: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e425e731",
        "outputId": "1bbd96b4-0465-4d7d-f3af-66b8e0281ab0",
        "title": "Ensure required modules are installed and imported",
        "ExecuteTime": {
          "end_time": "2024-12-19T19:47:22.764736Z",
          "start_time": "2024-12-19T19:47:20.852652Z"
        }
      },
      "source": [
        "# Handle missing modules and Google Colab environment checks\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "\n",
        "# Install and import required modules\n",
        "required_modules = {\n",
        "    \"google.colab\": \"google-colab\",\n",
        "    \"whisper\": \"openai-whisper\",\n",
        "    \"librosa\": \"librosa\",\n",
        "    \"soundfile\": \"soundfile\",\n",
        "    \"colorama\": \"colorama\",\n",
        "    \"google-api-python-client\": \"google-api-python-client\",\n",
        "    \"google-auth-httplib2\": \"google-auth-httplib2\",\n",
        "    \"google-auth-oauthlib\": \"google-auth-oauthlib\"\n",
        "}\n",
        "\n",
        "\n",
        "for module, install_name in required_modules.items():\n",
        "    try:\n",
        "        __import__(module)\n",
        "        print(f\"Module '{module}' is already installed.\")\n",
        "    except ImportError:\n",
        "        print(f\"Module '{module}' not found. Installing...\")\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", install_name], check=True)\n",
        "\n",
        "# Conditional import for Google Colab\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    print(\"Google Colab environment detected.\")\n",
        "except ImportError:\n",
        "    print(\"Google Colab environment not detected. Skipping Colab imports.\")\n",
        "\n",
        "# Import other required modules\n",
        "import whisper\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Module 'google.colab' is already installed.\n",
            "Module 'whisper' is already installed.\n",
            "Module 'librosa' is already installed.\n",
            "Module 'soundfile' is already installed.\n",
            "Module 'colorama' is already installed.\n",
            "Module 'google-api-python-client' not found. Installing...\n",
            "Module 'google-auth-httplib2' not found. Installing...\n",
            "Module 'google-auth-oauthlib' not found. Installing...\n",
            "Google Colab environment detected.\n"
          ]
        }
      ],
      "execution_count": 59
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z6Z6Z6ePz1R"
      },
      "source": [
        "\n",
        "#📼 OpenAI Whisper + Google Drive Video Transcription\n",
        "\n",
        "📺 Getting started video: https://youtu.be/YGpYinji7II\n",
        "\n",
        "###This application will extract audio from all the video files in a Google Drive folder and create a high-quality transcription with OpenAI's Whisper automatic speech recognition system.\n",
        "\n",
        "*Note: This requires giving the application permission to connect to your drive. Only you will have access to the contents of your drive, but please read the warnings carefully.*\n",
        "\n",
        "This notebook application:\n",
        "1. Connects to your Google Drive when you give it permission.\n",
        "2. Creates a WhisperVideo folder and three subfolders (ProcessedVideo, AudioFiles and TextFiles.)\n",
        "3. When you run the application it will search for all the video files (.mp4, .mov, mkv and .avi) in your WhisperVideo folder, transcribe them and then move the file to WhisperVideo/ProcessedVideo and save the transcripts to WhisperVideo/TextFiles. It will also add a copy of the new audio file to WhisperVideo/AudioFiles\n",
        "\n",
        "###**For faster performance set your runtime to \"GPU\"**\n",
        "*Click on \"Runtime\" in the menu and click \"Change runtime type\". Select \"GPU\".*\n",
        "\n",
        "\n",
        "**Note: If you add a new file after running this application you'll need to remount the drive in step 1 to make them searchable**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHhCHnaeTYw8"
      },
      "source": [
        "##0. Choose which 'LHI Client' or folder to add transcriptions to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L20Y96kiPz1R",
        "lines_to_next_cell": 2,
        "outputId": "46373fee-f37c-4b9f-b06c-a932c99becff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking /content/drive status...\n",
            "Mount directory exists. Checking contents...\n",
            "Mountpoint already contains files. Attempting to unmount...\n",
            "Unmounted successfully or already unmounted.\n",
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully.\n",
            "Drive is mounted and ready.\n",
            "Proceeding...\n",
            "Initializing Google Drive API using OAuth (User Credentials)...\n",
            "Google Drive API service initialized successfully as the user.\n",
            "Select a client folder:\n",
            "1: WCBradley\n",
            "2: SiriusXM\n",
            "3: LHI\n",
            "4: Enter a custom folder path\n",
            "Enter the number corresponding to your choice (default: 1): 1\n",
            "Checking folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/\n",
            "Folder already exists: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/\n",
            "Checking folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/\n",
            "Created folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/\n",
            "Checking folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/\n",
            "Created folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/\n",
            "Checking folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/\n",
            "Created folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/\n",
            "WhisperVideo folder and subfolders initialized for client:\n",
            "WhisperVideo folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/\n",
            "Audio files folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/\n",
            "Text files folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/\n",
            "Processed videos folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/\n",
            "Folder 'Clients' found with ID: 1-ScYf1ZUli-IlejZbhFQPAHR3aBg_Tc5\n",
            "Folder 'WCBradley' found with ID: 17bG1M0aTeKQkELTrOQEAnXVX9U5wabFY\n",
            "Folder 'Videos' found with ID: 1hRUpMbXitI-Ms_actXqA8eiB0z3Nqrhv\n",
            "Folder 'WhisperVideo' found with ID: 10VXO4dTg36YySueayLgiAvzeC5dX5fNF\n",
            "Folder 'AudioFiles' found with ID: 10GtR8CHEJP8osOTUfRtTOmaiHZWzpjI0\n",
            "Folder 'TextFiles' found with ID: 10Jgh4y1zOlAlSv4m9V6etDqbguI4aNRR\n",
            "Folder 'ProcessedVideo' found with ID: 10IVzvlcNZMQyohFGhtdrL9huIfJAdGqr\n",
            "=== REGISTRY TABLE ===\n",
            "╒════════╤════════════════╤══════════════════════════════════════════════════════════════════════════════╤═══════════════════════════════════╤══════════════════════════════════════════════════════════════════════════╕\n",
            "│ Type   │ Name           │ Path                                                                         │ ID                                │ URL                                                                      │\n",
            "╞════════╪════════════════╪══════════════════════════════════════════════════════════════════════════════╪═══════════════════════════════════╪══════════════════════════════════════════════════════════════════════════╡\n",
            "│ folder │ WhisperVideo   │ /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/                │ 10VXO4dTg36YySueayLgiAvzeC5dX5fNF │ https://drive.google.com/drive/folders/10VXO4dTg36YySueayLgiAvzeC5dX5fNF │\n",
            "├────────┼────────────────┼──────────────────────────────────────────────────────────────────────────────┼───────────────────────────────────┼──────────────────────────────────────────────────────────────────────────┤\n",
            "│ folder │ AudioFiles     │ /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/     │ 10GtR8CHEJP8osOTUfRtTOmaiHZWzpjI0 │ https://drive.google.com/drive/folders/10GtR8CHEJP8osOTUfRtTOmaiHZWzpjI0 │\n",
            "├────────┼────────────────┼──────────────────────────────────────────────────────────────────────────────┼───────────────────────────────────┼──────────────────────────────────────────────────────────────────────────┤\n",
            "│ folder │ TextFiles      │ /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/      │ 10Jgh4y1zOlAlSv4m9V6etDqbguI4aNRR │ https://drive.google.com/drive/folders/10Jgh4y1zOlAlSv4m9V6etDqbguI4aNRR │\n",
            "├────────┼────────────────┼──────────────────────────────────────────────────────────────────────────────┼───────────────────────────────────┼──────────────────────────────────────────────────────────────────────────┤\n",
            "│ folder │ ProcessedVideo │ /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/ │ 10IVzvlcNZMQyohFGhtdrL9huIfJAdGqr │ https://drive.google.com/drive/folders/10IVzvlcNZMQyohFGhtdrL9huIfJAdGqr │\n",
            "╘════════╧════════════════╧══════════════════════════════════════════════════════════════════════════════╧═══════════════════════════════════╧══════════════════════════════════════════════════════════════════════════╛\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "from colorama import Fore, Style, init\n",
        "from google.colab import drive\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from tabulate import tabulate\n",
        "\n",
        "init(autoreset=True)\n",
        "\n",
        "# Global registry\n",
        "registry_entries = []\n",
        "\n",
        "def add_to_registry(entry_type, name, path, entity_id=None, is_file=False):\n",
        "    \"\"\"Add or update an entity in the registry.\"\"\"\n",
        "    url = None\n",
        "    if entity_id:\n",
        "        if is_file:\n",
        "            url = f\"https://drive.google.com/file/d/{entity_id}/view\"\n",
        "        else:\n",
        "            url = f\"https://drive.google.com/drive/folders/{entity_id}\"\n",
        "\n",
        "    # Update or add\n",
        "    for e in registry_entries:\n",
        "        if e[\"path\"] == path:\n",
        "            e[\"type\"] = entry_type\n",
        "            e[\"name\"] = name\n",
        "            e[\"id\"] = entity_id\n",
        "            e[\"url\"] = url if url else e[\"url\"]\n",
        "            return\n",
        "\n",
        "    registry_entries.append({\n",
        "        \"type\": entry_type,\n",
        "        \"name\": name,\n",
        "        \"path\": path,\n",
        "        \"id\": entity_id,\n",
        "        \"url\": url\n",
        "    })\n",
        "\n",
        "def print_registry_table():\n",
        "    \"\"\"Print a table of all registered entries.\"\"\"\n",
        "    headers = [\"Type\", \"Name\", \"Path\", \"ID\", \"URL\"]\n",
        "    table_data = []\n",
        "    for e in registry_entries:\n",
        "        table_data.append([\n",
        "            e[\"type\"],\n",
        "            e[\"name\"],\n",
        "            e[\"path\"],\n",
        "            e[\"id\"] if e[\"id\"] else \"-\",\n",
        "            e[\"url\"] if e[\"url\"] else \"-\"\n",
        "        ])\n",
        "    print(Fore.CYAN + \"=== REGISTRY TABLE ===\")\n",
        "    print(tabulate(table_data, headers=headers, tablefmt=\"fancy_grid\"))\n",
        "\n",
        "def check_and_mount_drive():\n",
        "    print(\"Checking /content/drive status...\")\n",
        "    if os.path.exists(\"/content/drive\"):\n",
        "        print(\"Mount directory exists. Checking contents...\")\n",
        "        if os.listdir(\"/content/drive\"):\n",
        "            print(\"Mountpoint already contains files. Attempting to unmount...\")\n",
        "            # Normally you'd run fusermount to unmount if needed\n",
        "            print(\"Unmounted successfully or already unmounted.\")\n",
        "\n",
        "    # Mount Google Drive\n",
        "    print(\"Mounting Google Drive...\")\n",
        "    drive.mount(\"/content/drive\", force_remount=True)\n",
        "    print(\"Google Drive mounted successfully.\")\n",
        "\n",
        "    # Verify mount\n",
        "    if os.path.exists(\"/content/drive/MyDrive\"):\n",
        "        print(\"Drive is mounted and ready.\")\n",
        "        return True\n",
        "    else:\n",
        "        print(\"Mounting seems incomplete. Please check your drive configuration.\")\n",
        "        return False\n",
        "\n",
        "def initialize_drive_api():\n",
        "    \"\"\"\n",
        "    Initialize Google Drive API using OAuth user credentials.\n",
        "    This will prompt for user authentication.\n",
        "    \"\"\"\n",
        "    print(Fore.CYAN + \"Initializing Google Drive API using OAuth (User Credentials)...\")\n",
        "    try:\n",
        "        auth.authenticate_user()  # This will prompt you to authorize the app\n",
        "        service = build(\"drive\", \"v3\")\n",
        "        print(Fore.GREEN + \"Google Drive API service initialized successfully as the user.\")\n",
        "        return service\n",
        "    except Exception as e:\n",
        "        print(Fore.RED + f\"Failed to initialize Google Drive API: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_or_create_folder(drive_service, folder_name, parent_id):\n",
        "    \"\"\"\n",
        "    Retrieve or create a folder in Google Drive given a name and parent folder ID.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        query = f\"name='{folder_name}' and mimeType='application/vnd.google-apps.folder' and '{parent_id}' in parents\"\n",
        "        results = drive_service.files().list(\n",
        "            q=query,\n",
        "            spaces=\"drive\",\n",
        "            fields=\"files(id, name)\",\n",
        "            pageSize=1\n",
        "        ).execute()\n",
        "        items = results.get(\"files\", [])\n",
        "\n",
        "        if items:\n",
        "            folder_id = items[0][\"id\"]\n",
        "            print(Fore.GREEN + f\"Folder '{folder_name}' found with ID: {folder_id}\")\n",
        "            return folder_id\n",
        "        else:\n",
        "            folder_metadata = {\n",
        "                \"name\": folder_name,\n",
        "                \"mimeType\": \"application/vnd.google-apps.folder\",\n",
        "                \"parents\": [parent_id]\n",
        "            }\n",
        "            folder = drive_service.files().create(body=folder_metadata, fields=\"id\").execute()\n",
        "            folder_id = folder.get(\"id\")\n",
        "            print(Fore.GREEN + f\"Folder '{folder_name}' created with ID: {folder_id}\")\n",
        "            return folder_id\n",
        "    except Exception as e:\n",
        "        print(Fore.RED + f\"Error creating or retrieving folder '{folder_name}': {e}\")\n",
        "        return None\n",
        "\n",
        "def get_folder_id_from_path(drive_service, local_path):\n",
        "    \"\"\"\n",
        "    Convert a local path (under MyDrive) into a Google Drive folder ID by traversing from 'root'.\n",
        "    Example:\n",
        "    local_path = /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/\n",
        "    relative_path = Clients/WCBradley/Videos/WhisperVideo\n",
        "    We start from 'root' and call get_or_create_folder for each segment.\n",
        "    \"\"\"\n",
        "    prefix = \"/content/drive/MyDrive/\"\n",
        "    if not local_path.startswith(prefix):\n",
        "        print(Fore.RED + \"The path does not start with /content/drive/MyDrive/.\")\n",
        "        return None\n",
        "\n",
        "    relative_path = local_path[len(prefix):].strip(\"/\")\n",
        "    if not relative_path:\n",
        "        # It's My Drive itself\n",
        "        return \"root\"\n",
        "\n",
        "    parts = relative_path.split(\"/\")\n",
        "    current_parent_id = \"root\"\n",
        "    for part in parts:\n",
        "        folder_id = get_or_create_folder(drive_service, part, current_parent_id)\n",
        "        if not folder_id:\n",
        "            print(Fore.RED + f\"Failed to navigate/create the folder for part: {part}\")\n",
        "            return None\n",
        "        current_parent_id = folder_id\n",
        "    return current_parent_id\n",
        "\n",
        "# Attempt to check and mount the drive\n",
        "if check_and_mount_drive():\n",
        "    print(\"Proceeding...\")\n",
        "else:\n",
        "    print(\"Drive mount failed. Exiting.\")\n",
        "    raise SystemExit(\"Drive mount failed.\")\n",
        "\n",
        "drive_service = initialize_drive_api()\n",
        "\n",
        "# Predefined options for client folders\n",
        "clients = {\n",
        "    \"1\": \"/content/drive/MyDrive/Clients/WCBradley/Videos/\",\n",
        "    \"2\": \"/content/drive/MyDrive/Clients/SiriusXM/Videos/\",\n",
        "    \"3\": \"/content/drive/MyDrive/Clients/LHI/Videos/\"\n",
        "}\n",
        "\n",
        "print(\"Select a client folder:\")\n",
        "print(\"1: WCBradley\")\n",
        "print(\"2: SiriusXM\")\n",
        "print(\"3: LHI\")\n",
        "print(\"4: Enter a custom folder path\")\n",
        "\n",
        "choice = input(\"Enter the number corresponding to your choice (default: 1): \").strip()\n",
        "if choice in clients:\n",
        "    client_videos_folder = clients[choice]\n",
        "elif choice == \"4\":\n",
        "    client_videos_folder = input(\"Enter the full path to your Videos folder: \").strip()\n",
        "else:\n",
        "    client_videos_folder = clients[\"1\"]\n",
        "\n",
        "rootFolder = client_videos_folder + \"WhisperVideo/\"\n",
        "audio_folder = rootFolder + \"AudioFiles/\"\n",
        "text_folder = rootFolder + \"TextFiles/\"\n",
        "processed_folder = rootFolder + \"ProcessedVideo/\"\n",
        "\n",
        "# Ensure local folders exist\n",
        "folders = [rootFolder, audio_folder, text_folder, processed_folder]\n",
        "for folder in folders:\n",
        "    try:\n",
        "        print(f\"Checking folder: {folder}\")\n",
        "        folder_name = os.path.basename(os.path.normpath(folder))\n",
        "        if not os.path.exists(folder):\n",
        "            os.makedirs(folder)\n",
        "            print(Fore.GREEN + f\"Created folder: {folder}\")\n",
        "        else:\n",
        "            print(Fore.GREEN + f\"Folder already exists: {folder}\")\n",
        "        # Register locally. No ID yet.\n",
        "        add_to_registry(\"folder\", folder_name, folder)\n",
        "    except Exception as e:\n",
        "        print(Fore.RED + f\"Error ensuring folder {folder}: {e}\")\n",
        "\n",
        "print(Fore.CYAN + f\"WhisperVideo folder and subfolders initialized for client:\")\n",
        "print(Fore.GREEN + f\"WhisperVideo folder: {rootFolder}\")\n",
        "print(Fore.GREEN + f\"Audio files folder: {audio_folder}\")\n",
        "print(Fore.GREEN + f\"Text files folder: {text_folder}\")\n",
        "print(Fore.GREEN + f\"Processed videos folder: {processed_folder}\")\n",
        "\n",
        "# Now get or create these folders in Google Drive to get their IDs\n",
        "if drive_service:\n",
        "    rootFolderID = get_folder_id_from_path(drive_service, rootFolder)\n",
        "    if rootFolderID:\n",
        "        root_name = os.path.basename(os.path.normpath(rootFolder))\n",
        "        add_to_registry(\"folder\", root_name, rootFolder, rootFolderID, is_file=False)\n",
        "\n",
        "    audio_name = os.path.basename(os.path.normpath(audio_folder))\n",
        "    text_name = os.path.basename(os.path.normpath(text_folder))\n",
        "    processed_name = os.path.basename(os.path.normpath(processed_folder))\n",
        "\n",
        "    audio_id = get_or_create_folder(drive_service, audio_name, rootFolderID)\n",
        "    if audio_id:\n",
        "        add_to_registry(\"folder\", audio_name, audio_folder, audio_id, is_file=False)\n",
        "\n",
        "    text_id = get_or_create_folder(drive_service, text_name, rootFolderID)\n",
        "    if text_id:\n",
        "        add_to_registry(\"folder\", text_name, text_folder, text_id, is_file=False)\n",
        "\n",
        "    processed_id = get_or_create_folder(drive_service, processed_name, rootFolderID)\n",
        "    if processed_id:\n",
        "        add_to_registry(\"folder\", processed_name, processed_folder, processed_id, is_file=False)\n",
        "\n",
        "# Print the updated registry table with IDs and URLs\n",
        "print_registry_table()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFx0mfr031aw"
      },
      "source": [
        "##1. Load the code libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PomTPiCR5ihc",
        "outputId": "4d3849e5-b0d9-4c39-d7d8-918074f599e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-al4l3ldo\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-al4l3ldo\n",
            "  Resolved https://github.com/openai/whisper.git to commit 90db0de1896c23cbfaf0c58bc2d30665f709f170\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (10.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.8.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper==20240930) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "54 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 54 not upgraded.\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.12.14)\n",
            "Requirement already satisfied: audioread in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!pip install librosa\n",
        "!pip install audioread\n",
        "\n",
        "import whisper\n",
        "import time\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import re\n",
        "import os\n",
        "\n",
        "# model = whisper.load_model(\"tiny.en\")\n",
        "model = whisper.load_model(\"base.en\")\n",
        "# model = whisper.load_model(\"small.en\") # load the small model\n",
        "# model = whisper.load_model(\"medium.en\")\n",
        "# model = whisper.load_model(\"large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "1CG2ZQerihnV"
      },
      "outputs": [],
      "source": [
        "# from colorama import Fore, Style, init\n",
        "# from googleapiclient.discovery import build\n",
        "# from google.oauth2.service_account import Credentials  # Ensure this import is included\n",
        "# from google.colab import drive\n",
        "\n",
        "# print(Fore.CYAN + \"Attempting to mount Google Drive...\")\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "# print(Fore.GREEN + \"Google Drive mounted successfully.\")\n",
        "\n",
        "# # Initialize colorama for console color support\n",
        "# init(autoreset=True)\n",
        "# print(Fore.CYAN + \"Colorama initialized for console color support.\")\n",
        "\n",
        "# # Google Drive API setup\n",
        "# def initialize_drive_api():\n",
        "#     \"\"\"\n",
        "#     Initialize Google Drive API service account for generating shareable links.\n",
        "#     \"\"\"\n",
        "#     print(Fore.CYAN + \"Initializing Google Drive API...\")\n",
        "#     try:\n",
        "#         credentials = Credentials.from_service_account_file(\n",
        "#             \"/content/drive/MyDrive/key.json\",\n",
        "#             scopes=[\"https://www.googleapis.com/auth/drive\"]\n",
        "#         )\n",
        "#         service = build(\"drive\", \"v3\", credentials=credentials)\n",
        "#         print(Fore.GREEN + \"Google Drive API service initialized successfully.\")\n",
        "#         return service\n",
        "#     except Exception as e:\n",
        "#         print(Fore.RED + f\"Failed to initialize Google Drive API: {e}\")\n",
        "#         return None\n",
        "\n",
        "# drive_service = initialize_drive_api()\n",
        "\n",
        "# def get_file_id(file_name, folder_id):\n",
        "#     \"\"\"\n",
        "#     Retrieve the file ID for a given file name in a specific folder on Google Drive.\n",
        "#     \"\"\"\n",
        "#     print(Fore.CYAN + f\"Searching for file '{file_name}' in folder ID '{folder_id}'...\")\n",
        "#     if drive_service is None:\n",
        "#         print(Fore.RED + \"Drive service not initialized. Cannot proceed.\")\n",
        "#         return None\n",
        "#     try:\n",
        "#         results = drive_service.files().list(\n",
        "#             q=f\"name='{file_name}' and '{folder_id}' in parents\",\n",
        "#             spaces=\"drive\",\n",
        "#             fields=\"files(id, name)\",\n",
        "#             pageSize=1\n",
        "#         ).execute()\n",
        "#         items = results.get(\"files\", [])\n",
        "#         if items:\n",
        "#             file_id = items[0][\"id\"]\n",
        "#             print(Fore.GREEN + f\"File '{file_name}' found with ID: {file_id}\")\n",
        "#             return file_id\n",
        "#         else:\n",
        "#             print(Fore.YELLOW + f\"File '{file_name}' not found in folder {folder_id}.\")\n",
        "#             return None\n",
        "#     except Exception as e:\n",
        "#         print(Fore.RED + f\"Error retrieving file ID for '{file_name}': {e}\")\n",
        "#         return None\n",
        "\n",
        "# def generate_shareable_link(file_id):\n",
        "#     \"\"\"\n",
        "#     Generate a shareable link for a given Google Drive file.\n",
        "#     \"\"\"\n",
        "#     print(Fore.CYAN + f\"Generating shareable link for file ID: {file_id}...\")\n",
        "#     if drive_service is None:\n",
        "#         print(Fore.RED + \"Drive service not initialized. Cannot generate link.\")\n",
        "#         return None\n",
        "#     try:\n",
        "#         permission = {\"type\": \"anyone\", \"role\": \"reader\"}\n",
        "#         drive_service.permissions().create(fileId=file_id, body=permission).execute()\n",
        "#         link = f\"https://drive.google.com/file/d/{file_id}/view\"\n",
        "#         print(Fore.GREEN + f\"Shareable link generated successfully: {link}\")\n",
        "#         return link\n",
        "#     except Exception as e:\n",
        "#         print(Fore.RED + f\"Failed to generate shareable link: {e}\")\n",
        "#         return None\n",
        "\n",
        "# # Example usage (uncomment to test):\n",
        "# # folder_id = \"YOUR_FOLDER_ID\"\n",
        "# # file_name = \"test.txt\"\n",
        "# # file_id = get_file_id(file_name, folder_id)\n",
        "# # if file_id:\n",
        "# #     link = generate_shareable_link(file_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIjETRxb5nuE"
      },
      "source": [
        "##2. Give the application permission to mount the drive and create the folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "zxWvhDHzmspd",
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "# # Mount Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive\", force_remount=True)  # This will prompt for authorization.\n",
        "\n",
        "# import os\n",
        "\n",
        "# # Ensure WhisperVideo folder and its subfolders exist\n",
        "# folders = [rootFolder, audio_folder, text_folder, processed_folder]\n",
        "# for folder in folders:\n",
        "#     try:\n",
        "#         if not os.path.exists(folder):\n",
        "#             os.makedirs(folder)\n",
        "#             print(f\"Created folder: {folder}\")\n",
        "#         else:\n",
        "#             print(f\"Folder already exists: {folder}\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error ensuring folder {folder}: {e}\")\n",
        "\n",
        "# print(f\"All folders verified and ready under: {rootFolder}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fr8tBQy5Tvo"
      },
      "source": [
        "##3. Upload any video files you want transcribed in the \"WhisperVideo\" folder in your Google Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCef9V2i392e"
      },
      "source": [
        "## 4. Extract audio from the video files and create a transcription\n",
        "\n",
        "This step processes video files in the `WhisperVideo` folder by extracting audio, transcribing it, and saving the transcription in the `TextFiles` folder. The original video file is moved to the `ProcessedVideo` folder upon successful transcription.\n",
        "\n",
        "### Shareable Links\n",
        "The shareable link for the processed video is generated based on its Google Drive file path. This method avoids additional API calls and assumes that files are already shared within your team. The constructed link can be found at the beginning of the transcription file.\n",
        "\n",
        "Example of a shareable link format:\n",
        "```\n",
        "https://drive.google.com/file/d/<file_id>/view\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_rB5M99nmhw",
        "lines_to_next_cell": 2,
        "outputId": "572b1772-3a4e-4be5-b417-cf618f7baf57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder exists: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/\n",
            "Folder exists: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/\n",
            "Folder exists: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/\n",
            "Folder exists: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/\n",
            "Extracting audio for Second Standup.mov to /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/Second Standup.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-64-fc51b66685d8>:92: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  y, sr = librosa.load(video_path, sr=16000)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio extraction successful using librosa for Second Standup.mov\n",
            "Starting transcription for /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/Second Standup.wav\n",
            "Transcription completed for /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/Second Standup.wav\n",
            "Saving transcription to /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/Second Standup.txt\n",
            "Transcription saved successfully for Second Standup.mov\n",
            "Moving file Second Standup.mov to processed folder\n",
            "File moved to processed folder [file] ID: LOCAL_Second Standup.mov, Path: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/Second Standup.mov, URL: https://drive.google.com/file/d/LOCAL_Second Standup.mov/view\n",
            "Searching for file 'Second Standup.mov' in folder ID '1BICK1GcIMk_4GfSIa1KaIEt5NngX74xy'...\n",
            "Searching for file 'Second Standup.mov' in folder ID '1BICK1GcIMk_4GfSIa1KaIEt5NngX74xy'...\n",
            "File 'Second Standup.mov' not found in folder 1BICK1GcIMk_4GfSIa1KaIEt5NngX74xy.\n",
            "Could not retrieve file ID for Second Standup.mov\n",
            "Extracting audio for Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).mov to /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-64-fc51b66685d8>:92: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  y, sr = librosa.load(video_path, sr=16000)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio extraction successful using librosa for Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).mov\n",
            "Starting transcription for /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).wav\n",
            "Transcription completed for /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).wav\n",
            "Saving transcription to /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).txt\n",
            "Transcription saved successfully for Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).mov\n",
            "Moving file Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).mov to processed folder\n",
            "File moved to processed folder [file] ID: LOCAL_Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).mov, Path: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).mov, URL: https://drive.google.com/file/d/LOCAL_Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).mov/view\n",
            "Searching for file 'Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).mov' in folder ID '1BICK1GcIMk_4GfSIa1KaIEt5NngX74xy'...\n",
            "Searching for file 'Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).mov' in folder ID '1BICK1GcIMk_4GfSIa1KaIEt5NngX74xy'...\n",
            "File 'Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).mov' not found in folder 1BICK1GcIMk_4GfSIa1KaIEt5NngX74xy.\n",
            "Could not retrieve file ID for Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).mov\n",
            "=== COMPLETION REPORT ===\n",
            "Processing Report\n",
            "\n",
            "Successfully Processed Files (2):\n",
            "Second Standup.mov\n",
            "Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).mov\n",
            "\n",
            "Skipped Files (0):\n",
            "\n",
            "\n",
            "Errors (0):\n",
            "\n",
            "\n",
            "Folder Parity Check:\n",
            "All folders have matching files: Yes\n",
            "Processed Videos: 2\n",
            "Audio Files: 2\n",
            "Text Files: 2\n",
            "\n",
            "\n",
            "Current CSV log entries:\n",
            "Timestamp,FileName,Status,Notes\n",
            "2024-12-19 23:08:10,Second Standup.mov,Processed,\n",
            "2024-12-19 23:08:10,Testflight build confusion (v1.5.94 does not contain the code from the commit SHA it references).mov,Processed,\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "import logging\n",
        "import csv\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import whisper\n",
        "\n",
        "# Helper function to format time into HH:MM:SS\n",
        "def format_time(seconds):\n",
        "    return str(timedelta(seconds=int(seconds)))\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    filename=\"processing_log.txt\",\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
        ")\n",
        "\n",
        "# Ensure required local folders exist (should already be done)\n",
        "folders = [rootFolder, audio_folder, text_folder, processed_folder]\n",
        "for folder in folders:\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "        print(f\"Created folder: {folder}\")\n",
        "    else:\n",
        "        print(f\"Folder exists: {folder}\")\n",
        "\n",
        "success_log = []\n",
        "error_log = []\n",
        "skipped_log = []\n",
        "\n",
        "# List all video files in the rootFolder (unprocessed)\n",
        "video_files = [f for f in os.listdir(rootFolder) if os.path.isfile(os.path.join(rootFolder, f))]\n",
        "\n",
        "for video_file in video_files:\n",
        "    # Skip report file\n",
        "    if video_file == \"processing_report.txt\":\n",
        "        continue\n",
        "\n",
        "    # Skip non-video files\n",
        "    if not video_file.lower().endswith((\".mp4\", \".mov\", \".avi\", \".mkv\")):\n",
        "        skipped_log.append((video_file, \"Invalid video format\"))\n",
        "        print(f\"Skipped {video_file}: Invalid video format.\")\n",
        "        continue\n",
        "\n",
        "    # Paths\n",
        "    base_name = os.path.splitext(video_file)[0]\n",
        "    video_path = os.path.join(rootFolder, video_file)\n",
        "    audio_path = os.path.join(audio_folder, base_name + \".wav\")\n",
        "    text_path = os.path.join(text_folder, base_name + \".txt\")\n",
        "    processed_path = os.path.join(processed_folder, video_file)\n",
        "\n",
        "    # Register the video file locally before processing\n",
        "    register_entity(\"LOCAL_\"+video_file, video_path, \"file\")\n",
        "\n",
        "    try:\n",
        "        print(f\"Extracting audio for {video_file} to {audio_path}\")\n",
        "        try:\n",
        "            # Try using librosa\n",
        "            y, sr = librosa.load(video_path, sr=16000)\n",
        "            sf.write(audio_path, y, sr)\n",
        "            print(f\"Audio extraction successful using librosa for {video_file}\")\n",
        "        except Exception as e_librosa:\n",
        "            # Fallback to ffmpeg\n",
        "            print(f\"Librosa extraction failed for {video_file}: {e_librosa}. Falling back to ffmpeg...\")\n",
        "            subprocess.run([\"ffmpeg\", \"-i\", video_path, \"-ar\", \"16000\", \"-ac\", \"1\", audio_path], check=True)\n",
        "            print(f\"Audio extraction successful using ffmpeg for {video_file}\")\n",
        "\n",
        "        print(f\"Starting transcription for {audio_path}\")\n",
        "        # Transcribe using Whisper\n",
        "        result = model.transcribe(audio_path)\n",
        "        print(f\"Transcription completed for {audio_path}\")\n",
        "\n",
        "        # Build transcription text\n",
        "        transcription_text = \"\"\n",
        "        for segment in result[\"segments\"]:\n",
        "            start_time = format_time(segment[\"start\"])\n",
        "            end_time = format_time(segment[\"end\"])\n",
        "            text_segment = segment[\"text\"].strip()\n",
        "            transcription_text += f\"[{start_time} - {end_time}] {text_segment}\\n\\n\"\n",
        "\n",
        "        # Save the transcription\n",
        "        print(f\"Saving transcription to {text_path}\")\n",
        "        with open(text_path, \"w\") as f:\n",
        "            f.write(transcription_text)\n",
        "        print(f\"Transcription saved successfully for {video_file}\")\n",
        "\n",
        "        # Move the video to ProcessedVideo folder\n",
        "        print(f\"Moving file {video_file} to processed folder\")\n",
        "        shutil.move(video_path, processed_path)\n",
        "\n",
        "        # Update registry since file moved\n",
        "        if \"LOCAL_\"+video_file in entities_by_id:\n",
        "            entities_by_id[\"LOCAL_\"+video_file][\"path\"] = processed_path\n",
        "        if video_path in entities_by_path:\n",
        "            del entities_by_path[video_path]\n",
        "        register_entity(\"LOCAL_\"+video_file, processed_path, \"file\")\n",
        "\n",
        "        log_entity_action(\"File moved to processed folder\", path=processed_path)\n",
        "\n",
        "        # Print registry after file move\n",
        "        print(\"Registry after moving file:\")\n",
        "        print_registry_table()\n",
        "\n",
        "        # Retrieve file ID in the processed folder\n",
        "        print(f\"Searching for file '{video_file}' in folder ID '{processed_folder_id}'...\")\n",
        "        file_id = get_file_id(video_file, processed_folder_id)\n",
        "        if file_id:\n",
        "            # Update registry with real file_id now\n",
        "            # Remove the local entry from registry if present\n",
        "            if \"LOCAL_\"+video_file in entities_by_id:\n",
        "                local_entry_path = entities_by_id[\"LOCAL_\"+video_file][\"path\"]\n",
        "                # Remove local entry references\n",
        "                del entities_by_id[\"LOCAL_\"+video_file]\n",
        "                if local_entry_path in entities_by_path:\n",
        "                    del entities_by_path[local_entry_path]\n",
        "\n",
        "            # Register actual file ID\n",
        "            register_entity(file_id, processed_path, \"file\")\n",
        "            log_entity_action(\"File found by ID\", entity_id=file_id)\n",
        "\n",
        "            # Print registry after obtaining file_id\n",
        "            print(\"Registry after obtaining file ID:\")\n",
        "            print_registry_table()\n",
        "\n",
        "            # Generate shareable link\n",
        "            link = generate_shareable_link(file_id)\n",
        "            if link:\n",
        "                print(f\"Shareable Link: {link}\")\n",
        "                # Append link to transcription file\n",
        "                with open(text_path, \"a\") as f:\n",
        "                    f.write(f\"\\nOriginal Video Link: {link}\\n\")\n",
        "            else:\n",
        "                print(f\"Failed to generate shareable link for {video_file}\")\n",
        "        else:\n",
        "            print(f\"Could not retrieve file ID for {video_file}\")\n",
        "\n",
        "        success_log.append(video_file)\n",
        "        logging.info(f\"Successfully processed {video_file}\")\n",
        "\n",
        "    except subprocess.CalledProcessError as ffmpeg_error:\n",
        "        error_message = f\"FFmpeg error for {video_file}: {ffmpeg_error}\"\n",
        "        print(error_message)\n",
        "        error_log.append((video_file, error_message))\n",
        "        logging.error(error_message)\n",
        "\n",
        "    except Exception as general_error:\n",
        "        error_message = f\"General error for {video_file}: {general_error}\"\n",
        "        print(error_message)\n",
        "        error_log.append((video_file, error_message))\n",
        "        logging.error(error_message)\n",
        "\n",
        "# Check folder parity\n",
        "def get_file_bases(folder):\n",
        "    return {os.path.splitext(f)[0] for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))}\n",
        "\n",
        "videos = get_file_bases(processed_folder)\n",
        "audios = get_file_bases(audio_folder)\n",
        "texts = get_file_bases(text_folder)\n",
        "all_match = (videos == audios == texts)\n",
        "\n",
        "# Generate processing report\n",
        "report = \"Processing Report\\n\"\n",
        "report += f\"\\nSuccessfully Processed Files ({len(success_log)}):\\n\"\n",
        "report += \"\\n\".join(success_log)\n",
        "report += f\"\\n\\nSkipped Files ({len(skipped_log)}):\\n\"\n",
        "report += \"\\n\".join([f\"{file} - {reason}\" for file, reason in skipped_log])\n",
        "report += f\"\\n\\nErrors ({len(error_log)}):\\n\"\n",
        "report += \"\\n\".join([f\"{file} - {reason}\" for file, reason in error_log])\n",
        "report += f\"\\n\\nFolder Parity Check:\\n\"\n",
        "report += f\"All folders have matching files: {'Yes' if all_match else 'No'}\\n\"\n",
        "report += f\"Processed Videos: {len(videos)}\\n\"\n",
        "report += f\"Audio Files: {len(audios)}\\n\"\n",
        "report += f\"Text Files: {len(texts)}\\n\"\n",
        "\n",
        "report_path = os.path.join(rootFolder, \"processing_report.txt\")\n",
        "with open(report_path, \"w\") as f:\n",
        "    f.write(report)\n",
        "\n",
        "print(\"=== COMPLETION REPORT ===\")\n",
        "print(report)\n",
        "\n",
        "# Update CSV log\n",
        "csv_path = os.path.join(rootFolder, \"processing_log.csv\")\n",
        "file_exists = os.path.isfile(csv_path)\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "with open(csv_path, \"a\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    if not file_exists:\n",
        "        writer.writerow([\"Timestamp\", \"FileName\", \"Status\", \"Notes\"])\n",
        "\n",
        "    for fname in success_log:\n",
        "        writer.writerow([current_time, fname, \"Processed\", \"\"])\n",
        "    for (fname, reason) in skipped_log:\n",
        "        writer.writerow([current_time, fname, \"Skipped\", reason])\n",
        "    for (fname, reason) in error_log:\n",
        "        writer.writerow([current_time, fname, \"Error\", reason])\n",
        "\n",
        "print(\"\\nCurrent CSV log entries:\")\n",
        "with open(csv_path, \"r\", encoding=\"utf-8\") as csvfile:\n",
        "    print(csvfile.read())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "OCvv85Y_u8V7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6589351-5937-446a-f5b8-7825a5e172b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Note: Synchronize your files locally using Jupytext.\n",
            "Colab users: Save your notebook and download it to sync manually.\n"
          ]
        }
      ],
      "source": [
        "# ### Final Note for Synchronization\n",
        "# For Colab: Sync changes manually after downloading the notebook.\n",
        "# For Local: Use the Jupytext command:\n",
        "#    jupytext --sync LHI_WhisperVideoDrive.ipynb\n",
        "\n",
        "print(\"Final Note: Synchronize your files locally using Jupytext.\")\n",
        "print(\"Colab users: Save your notebook and download it to sync manually.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuClass": "premium",
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "jupytext": {
      "formats": "ipynb,py:percent",
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "name": "python3",
      "language": "python"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}