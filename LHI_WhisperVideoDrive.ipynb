{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LifeHackInnovationsLLC/whisper-video-transcription/blob/main/LHI_WhisperVideoDrive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you're looking at this on GitHub and new to Python Notebooks or Colab, click the Google Colab badge above 👆\n",
        "\n",
        "#📼 OpenAI Whisper + Google Drive Video Transcription\n",
        "\n",
        "📺 Getting started video: https://youtu.be/YGpYinji7II\n",
        "\n",
        "###This application will extract audio from all the video files in a Google Drive folder and create a high-quality transcription with OpenAI's Whisper automatic speech recognition system.\n",
        "\n",
        "*Note: This requires giving the application permission to connect to your drive. Only you will have access to the contents of your drive, but please read the warnings carefully.*\n",
        "\n",
        "This notebook application:\n",
        "1. Connects to your Google Drive when you give it permission.\n",
        "2. Creates a WhisperVideo folder and three subfolders (ProcessedVideo, AudioFiles and TextFiles.)\n",
        "3. When you run the application it will search for all the video files (.mp4, .mov, mkv and .avi) in your WhisperVideo folder, transcribe them and then move the file to WhisperVideo/ProcessedVideo and save the transcripts to WhisperVideo/TextFiles. It will also add a copy of the new audio file to WhisperVideo/AudioFiles\n",
        "\n",
        "###**For faster performance set your runtime to \"GPU\"**\n",
        "*Click on \"Runtime\" in the menu and click \"Change runtime type\". Select \"GPU\".*\n",
        "\n",
        "\n",
        "**Note: If you add a new file after running this application you'll need to remount the drive in step 1 to make them searchable**"
      ],
      "metadata": {
        "id": "oSzWV5We2jx0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup & Mount Drive"
      ],
      "metadata": {
        "id": "DHhCHnaeTYw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Reusable function to check and mount Google Drive\n",
        "def check_and_mount_drive():\n",
        "    print(\"Checking /content/drive status...\")\n",
        "    if os.path.exists(\"/content/drive\"):\n",
        "        print(\"Mount directory exists. Checking contents...\")\n",
        "        if os.listdir(\"/content/drive\"):\n",
        "            print(\"Mountpoint already contains files. Attempting to unmount...\")\n",
        "            try:\n",
        "                # Unmount the existing mountpoint\n",
        "                !fusermount -u /content/drive\n",
        "                print(\"Unmounted successfully.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to unmount: {e}\")\n",
        "                print(\"If the issue persists, please select 'Runtime > Disconnect and delete runtime' and try again.\")\n",
        "                return False\n",
        "\n",
        "    # Mount Google Drive\n",
        "    print(\"Mounting Google Drive...\")\n",
        "    from google.colab import drive\n",
        "    try:\n",
        "        drive.mount(\"/content/drive\", force_remount=True)\n",
        "        print(\"Google Drive mounted successfully.\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Mounting failed: {e}\")\n",
        "        print(\"If the issue persists, please select 'Runtime > Disconnect and delete runtime' and try again.\")\n",
        "        return False\n",
        "\n",
        "    # Verify mount\n",
        "    if os.path.exists(\"/content/drive/MyDrive\"):\n",
        "        print(\"Drive is mounted and ready.\")\n",
        "        return True\n",
        "    else:\n",
        "        print(\"Mounting seems incomplete. Please check your drive configuration.\")\n",
        "        return False\n",
        "\n",
        "# Attempt to check and mount the drive\n",
        "if check_and_mount_drive():\n",
        "    print(\"Proceeding with folder creation...\")\n",
        "else:\n",
        "    print(\"Drive mount failed. Cannot proceed.\")\n",
        "    raise SystemExit(\"Drive mount failed. Exiting.\")\n",
        "\n",
        "# Predefined options for client folders\n",
        "clients = {\n",
        "    \"1\": \"/content/drive/MyDrive/Clients/WCBradley/Videos/\",\n",
        "    \"2\": \"/content/drive/MyDrive/Clients/SiriusXM/Videos/\",\n",
        "    \"3\": \"/content/drive/MyDrive/Clients/LHI/Videos/\"\n",
        "}\n",
        "\n",
        "# Display options to the user\n",
        "print(\"Select a client folder:\")\n",
        "print(\"1: WCBradley\")\n",
        "print(\"2: SiriusXM\")\n",
        "print(\"3: LHI\")\n",
        "print(\"4: Enter a custom folder path\")\n",
        "\n",
        "# Get user input\n",
        "choice = input(\"Enter the number corresponding to your choice (default: 1): \").strip()\n",
        "\n",
        "# Determine the root folder for the client\n",
        "if choice in clients:\n",
        "    client_videos_folder = clients[choice]\n",
        "elif choice == \"4\":\n",
        "    client_videos_folder = input(\"Enter the full path to your Videos folder: \").strip()\n",
        "else:\n",
        "    # Default to WCBradley if no valid input\n",
        "    client_videos_folder = clients[\"1\"]\n",
        "\n",
        "# Define the WhisperVideo root folder within the client's Videos folder\n",
        "rootFolder = client_videos_folder + \"WhisperVideo/\"\n",
        "\n",
        "# Define subfolder paths relative to the WhisperVideo root folder\n",
        "audio_folder = rootFolder + \"AudioFiles/\"\n",
        "text_folder = rootFolder + \"TextFiles/\"\n",
        "processed_folder = rootFolder + \"ProcessedVideo/\"\n",
        "\n",
        "# Ensure WhisperVideo folder and its subfolders exist\n",
        "folders = [rootFolder, audio_folder, text_folder, processed_folder]\n",
        "for folder in folders:\n",
        "    try:\n",
        "        print(f\"Checking folder: {folder}\")\n",
        "        if not os.path.exists(folder):\n",
        "            os.makedirs(folder)\n",
        "            print(f\"Created folder: {folder}\")\n",
        "        else:\n",
        "            print(f\"Folder already exists: {folder}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error ensuring folder {folder}: {e}\")\n",
        "\n",
        "print(f\"WhisperVideo folder and subfolders initialized for client:\")\n",
        "print(f\"WhisperVideo folder: {rootFolder}\")\n",
        "print(f\"Audio files folder: {audio_folder}\")\n",
        "print(f\"Text files folder: {text_folder}\")\n",
        "print(f\"Processed videos folder: {processed_folder}\")\n"
      ],
      "metadata": {
        "id": "L20Y96kiPz1R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e1328a9-716d-4b43-8e20-2a632835cb4c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking /content/drive status...\n",
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully.\n",
            "Drive is mounted and ready.\n",
            "Proceeding with folder creation...\n",
            "Select a client folder:\n",
            "1: WCBradley\n",
            "2: SiriusXM\n",
            "3: LHI\n",
            "4: Enter a custom folder path\n",
            "Enter the number corresponding to your choice (default: 1): 1\n",
            "Checking folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/\n",
            "Folder already exists: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/\n",
            "Checking folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/\n",
            "Folder already exists: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/\n",
            "Checking folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/\n",
            "Folder already exists: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/\n",
            "Checking folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/\n",
            "Folder already exists: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/\n",
            "WhisperVideo folder and subfolders initialized for client:\n",
            "WhisperVideo folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/\n",
            "Audio files folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/\n",
            "Text files folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/\n",
            "Processed videos folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Dependencies & Model Loading\n"
      ],
      "metadata": {
        "id": "pFx0mfr031aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!pip install librosa\n",
        "!pip install audioread\n",
        "\n",
        "import whisper\n",
        "import time\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import re\n",
        "import os\n",
        "\n",
        "# model = whisper.load_model(\"tiny.en\")\n",
        "model = whisper.load_model(\"base.en\")\n",
        "# model = whisper.load_model(\"small.en\") # load the small model\n",
        "# model = whisper.load_model(\"medium.en\")\n",
        "# model = whisper.load_model(\"large\")"
      ],
      "metadata": {
        "id": "PomTPiCR5ihc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "212ec79c-8192-4009-dabc-f404ba3d27d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-hjw6ifmt\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-hjw6ifmt\n",
            "  Resolved https://github.com/openai/whisper.git to commit 90db0de1896c23cbfaf0c58bc2d30665f709f170\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (4.66.6)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (10.5.0)\n",
            "Collecting tiktoken (from openai-whisper==20240930)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting triton>=2.0.0 (from openai-whisper==20240930)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper==20240930) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803583 sha256=9743a1a0f7ade516eed28406570e5b627ad2db6f881b224da1a5acd62b4e9043\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ytpcvdb3/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: triton, tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20240930 tiktoken-0.8.0 triton-3.1.0\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,626 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,225 kB]\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,531 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [32.9 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,514 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [49.7 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,331 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,458 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,453 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,741 kB]\n",
            "Fetched 26.4 MB in 3s (9,770 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "51 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n",
            "Requirement already satisfied: audioread in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:08<00:00, 16.4MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Processing Logic (Transcription)\n"
      ],
      "metadata": {
        "id": "JIjETRxb5nuE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zxWvhDHzmspd"
      },
      "outputs": [],
      "source": [
        "# # Mount Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive\", force_remount=True)  # This will prompt for authorization.\n",
        "\n",
        "# import os\n",
        "\n",
        "# # Ensure WhisperVideo folder and its subfolders exist\n",
        "# folders = [rootFolder, audio_folder, text_folder, processed_folder]\n",
        "# for folder in folders:\n",
        "#     try:\n",
        "#         if not os.path.exists(folder):\n",
        "#             os.makedirs(folder)\n",
        "#             print(f\"Created folder: {folder}\")\n",
        "#         else:\n",
        "#             print(f\"Folder already exists: {folder}\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error ensuring folder {folder}: {e}\")\n",
        "\n",
        "# print(f\"All folders verified and ready under: {rootFolder}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Reporting & CSV Logging\n"
      ],
      "metadata": {
        "id": "7fr8tBQy5Tvo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. (Future) Drive API Integration\n"
      ],
      "metadata": {
        "id": "nCef9V2i392e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from datetime import timedelta\n",
        "import subprocess\n",
        "import logging\n",
        "import csv\n",
        "from datetime import datetime\n",
        "# Removed: from urllib.parse import quote\n",
        "\n",
        "# Helper function to format time\n",
        "def format_time(seconds):\n",
        "    \"\"\"Convert seconds to HH:MM:SS format.\"\"\"\n",
        "    return str(timedelta(seconds=int(seconds)))\n",
        "\n",
        "# Removed the generate_shareable_link function\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    filename=\"processing_log.txt\",\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
        ")\n",
        "\n",
        "# Ensure folders are created\n",
        "folders = [rootFolder, audio_folder, text_folder, processed_folder]\n",
        "for folder in folders:\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "\n",
        "# Initialize logs\n",
        "success_log = []\n",
        "error_log = []\n",
        "skipped_log = []\n",
        "\n",
        "# Process all video files in WhisperVideo folder\n",
        "video_files = [f for f in os.listdir(rootFolder) if os.path.isfile(os.path.join(rootFolder, f))]\n",
        "\n",
        "for video_file in video_files:\n",
        "    # Exclude the report file from processing\n",
        "    if video_file == \"processing_report.txt\":\n",
        "        continue\n",
        "\n",
        "    # Skip non-video files\n",
        "    if not video_file.endswith((\".mp4\", \".mov\", \".avi\", \".mkv\")):\n",
        "        skipped_log.append((video_file, \"Invalid format\"))\n",
        "        print(f\"Skipped {video_file}: Invalid format.\")\n",
        "        continue\n",
        "\n",
        "    # Define paths\n",
        "    video_path = os.path.join(rootFolder, video_file)\n",
        "    audio_path = os.path.join(audio_folder, video_file[:-4] + \".wav\")\n",
        "    text_path = os.path.join(text_folder, video_file[:-4] + \".txt\")\n",
        "    processed_path = os.path.join(processed_folder, video_file)\n",
        "\n",
        "    try:\n",
        "        print(f\"Extracting audio for {video_file} to {audio_path}\")\n",
        "        # Extract audio\n",
        "        try:\n",
        "            # Attempt to load the audio using librosa\n",
        "            y, sr = librosa.load(video_path, sr=16000)  # Load audio with 16 kHz sampling rate\n",
        "            sf.write(audio_path, y, sr)  # Save audio as a WAV file\n",
        "            print(f\"Audio extraction successful using librosa for {video_file}\")\n",
        "        except Exception as e_librosa:\n",
        "            print(f\"Librosa extraction failed for {video_file}: {e_librosa}\")\n",
        "            print(f\"Falling back to ffmpeg for {video_file}\")\n",
        "            # Use ffmpeg as a fallback\n",
        "            subprocess.run([\"ffmpeg\", \"-i\", video_path, \"-ar\", \"16000\", \"-ac\", \"1\", audio_path], check=True)\n",
        "            print(f\"Audio extraction successful using ffmpeg for {video_file}\")\n",
        "\n",
        "        print(f\"Starting transcription for {audio_path}\")\n",
        "        # Transcribe the audio using Whisper\n",
        "        result = model.transcribe(audio_path)\n",
        "        print(f\"Transcription completed for {audio_path}\")\n",
        "\n",
        "        # Create initial transcription\n",
        "        text = \"\"\n",
        "        for segment in result[\"segments\"]:\n",
        "            start_time = format_time(segment[\"start\"])\n",
        "            end_time = format_time(segment[\"end\"])\n",
        "            text_segment = segment[\"text\"].strip()\n",
        "            text += f\"[{start_time} - {end_time}] {text_segment}\\n\\n\"\n",
        "\n",
        "        print(f\"Saving transcription to {text_path}\")\n",
        "        # Save the transcription\n",
        "        with open(text_path, \"w\") as f:\n",
        "            f.write(text)\n",
        "        print(f\"Transcription saved successfully for {video_file}\")\n",
        "\n",
        "        print(f\"Moving file {video_file} to processed folder\")\n",
        "        # Move the video to ProcessedVideo folder\n",
        "        shutil.move(video_path, processed_path)\n",
        "        print(f\"File moved to processed folder: {processed_path}\")\n",
        "\n",
        "        # Log success\n",
        "        success_log.append(video_file)\n",
        "        logging.info(f\"Successfully processed {video_file}\")\n",
        "        print(f\"Successfully processed {video_file}\")\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        error_message = f\"FFmpeg error for {video_file}: {e}\"\n",
        "        print(error_message)\n",
        "        error_log.append((video_file, error_message))\n",
        "        logging.error(error_message)\n",
        "    except Exception as e:\n",
        "        error_message = f\"General error for {video_file}: {e}\"\n",
        "        print(error_message)\n",
        "        error_log.append((video_file, error_message))\n",
        "        logging.error(error_message)\n",
        "\n",
        "# Perform folder parity check\n",
        "def get_file_bases(folder):\n",
        "    return {os.path.splitext(f)[0] for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))}\n",
        "\n",
        "videos = get_file_bases(processed_folder)\n",
        "audios = get_file_bases(audio_folder)\n",
        "texts = get_file_bases(text_folder)\n",
        "\n",
        "all_match = videos == audios == texts\n",
        "\n",
        "# Generate completion report\n",
        "report = \"Processing Report\\n\"\n",
        "report += f\"\\nSuccessfully Processed Files ({len(success_log)}):\\n\"\n",
        "report += \"\\n\".join(success_log)\n",
        "\n",
        "report += f\"\\n\\nSkipped Files ({len(skipped_log)}):\\n\"\n",
        "report += \"\\n\".join([f\"{file} - {reason}\" for file, reason in skipped_log])\n",
        "\n",
        "report += f\"\\n\\nErrors ({len(error_log)}):\\n\"\n",
        "report += \"\\n\".join([f\"{file} - {reason}\" for file, reason in error_log])\n",
        "\n",
        "report += f\"\\n\\nFolder Parity Check:\\n\"\n",
        "report += f\"All folders have matching files: {'Yes' if all_match else 'No'}\\n\"\n",
        "report += f\"Processed Videos: {len(videos)}\\n\"\n",
        "report += f\"Audio Files: {len(audios)}\\n\"\n",
        "report += f\"Text Files: {len(texts)}\\n\"\n",
        "\n",
        "# Save the report\n",
        "report_path = os.path.join(rootFolder, \"processing_report.txt\")\n",
        "with open(report_path, \"w\") as f:\n",
        "    f.write(report)\n",
        "\n",
        "# Display completion report\n",
        "print(report)\n",
        "\n",
        "csv_path = os.path.join(rootFolder, \"processing_log.csv\")\n",
        "file_exists = os.path.isfile(csv_path)\n",
        "\n",
        "# We'll store a timestamp for each run and each file processed/skipped/error\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "with open(csv_path, \"a\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    # If file doesn't exist, write header\n",
        "    if not file_exists:\n",
        "        writer.writerow([\"Timestamp\", \"FileName\", \"Status\", \"Notes\"])\n",
        "\n",
        "    # Append rows for each processed file\n",
        "    for fname in success_log:\n",
        "        writer.writerow([current_time, fname, \"Processed\", \"\"])\n",
        "\n",
        "    # Append rows for each skipped file\n",
        "    for (fname, reason) in skipped_log:\n",
        "        writer.writerow([current_time, fname, \"Skipped\", reason])\n",
        "\n",
        "    # Append rows for each error file\n",
        "    for (fname, reason) in error_log:\n",
        "        writer.writerow([current_time, fname, \"Error\", reason])\n",
        "\n",
        "print(\"\\nCurrent CSV log entries:\")\n",
        "with open(csv_path, \"r\", encoding=\"utf-8\") as csvfile:\n",
        "    print(csvfile.read())\n"
      ],
      "metadata": {
        "id": "D_rB5M99nmhw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a84e9d64-fe89-476a-fd76-502d01a77e30"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting audio for Production Deployment API Cosmos Telemetry Etc Allyssa Screen Recording 2024-06-28 at 2.22.03 PM.mov to /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/Production Deployment API Cosmos Telemetry Etc Allyssa Screen Recording 2024-06-28 at 2.22.03 PM.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-8afb492a4905>:60: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  y, sr = librosa.load(video_path, sr=16000)  # Load audio with 16 kHz sampling rate\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio extraction successful using librosa for Production Deployment API Cosmos Telemetry Etc Allyssa Screen Recording 2024-06-28 at 2.22.03 PM.mov\n",
            "Starting transcription for /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/Production Deployment API Cosmos Telemetry Etc Allyssa Screen Recording 2024-06-28 at 2.22.03 PM.wav\n",
            "Transcription completed for /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/AudioFiles/Production Deployment API Cosmos Telemetry Etc Allyssa Screen Recording 2024-06-28 at 2.22.03 PM.wav\n",
            "Saving transcription to /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/TextFiles/Production Deployment API Cosmos Telemetry Etc Allyssa Screen Recording 2024-06-28 at 2.22.03 PM.txt\n",
            "Transcription saved successfully for Production Deployment API Cosmos Telemetry Etc Allyssa Screen Recording 2024-06-28 at 2.22.03 PM.mov\n",
            "Moving file Production Deployment API Cosmos Telemetry Etc Allyssa Screen Recording 2024-06-28 at 2.22.03 PM.mov to processed folder\n",
            "File moved to processed folder: /content/drive/MyDrive/Clients/WCBradley/Videos/WhisperVideo/ProcessedVideo/Production Deployment API Cosmos Telemetry Etc Allyssa Screen Recording 2024-06-28 at 2.22.03 PM.mov\n",
            "Successfully processed Production Deployment API Cosmos Telemetry Etc Allyssa Screen Recording 2024-06-28 at 2.22.03 PM.mov\n",
            "Processing Report\n",
            "\n",
            "Successfully Processed Files (1):\n",
            "Production Deployment API Cosmos Telemetry Etc Allyssa Screen Recording 2024-06-28 at 2.22.03 PM.mov\n",
            "\n",
            "Skipped Files (0):\n",
            "\n",
            "\n",
            "Errors (0):\n",
            "\n",
            "\n",
            "Folder Parity Check:\n",
            "All folders have matching files: Yes\n",
            "Processed Videos: 9\n",
            "Audio Files: 9\n",
            "Text Files: 9\n",
            "\n",
            "\n",
            "Current CSV log entries:\n",
            "Timestamp,FileName,Status,Notes\n",
            "2024-12-09 18:04:57,Production Deployment API Cosmos Telemetry Etc Allyssa Screen Recording 2024-06-28 at 2.22.03 PM.mov,Processed,\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OCvv85Y_u8V7"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}